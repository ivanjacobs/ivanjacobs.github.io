{
  "hash": "2ba559e2eddb1d50208ca2f5798b0577",
  "result": {
    "markdown": "---\ntitle: \"Are tumors patient specific\"\nauthor: \"Ivan Jacobs\"\ndate: \\today\ncategories: [Personalized therapy, networks, machine learning, deep learning]\nimage: \"Figure 2.jpeg\"\nexecute:\n  echo: false\n---\n\n\n# Are tumors patient specific\n\nTo address this question we compare the characteristics and derived network measures of antibody--peptide epitopes for patient 1 and patient 2 to show the patient-specific nature of tumors expressed through peptides originating from tumor-induced mutations. To do so, we apply statistical analysis techniques such as multivariate analysis of variance (MANOVA) on the network measures to evaluate if they are statistically significantly different per patient. In addition, we look at how different network measures correlate with PMBC values per patient. We apply a structure learning algorithm to the data to learn the structure of the directed acyclic graph (DAG) to analyze the causality of data features, i.e., network measures and the matched PBMC values. Finally, we compare the performance of personalized models on unseen data from different patients to understand if models can generalize over unseen data from different patients.\n\n# Data Structure\n\nWe chose a network representation with layers to study the diverse relations and interactions between the components. These network representations are called multiplex networks, where a node corresponds to a \\\"physical object,\\\" while node-layer pairs are different instances of the same object.\n\nFor instance, a node could represent an online user, while node-layer pairs would represent different accounts of the same user in different online social networks; or a node could represent a social actor, while node-layer pairs would represent different social roles (e.g., friend, worker, and family member) of the same social actor; or a node could stand for a location in a transportation network, while node-layer pairs would represent stations of different transportation modes (e.g., streets, highways, and subways).\n\nThe connection between nodes and node-layer pairs is given by the notion of supra-nodes: i.e., cliques in the supra-graph formed by node-layer pairs that are instances of the same object. To correctly represent a physical object in the different layers of the multiplex network, we break down the peptides into amino acids and the amino acids to their smallest component atoms and their connection bonds. The layers coordinate, atom, monomer, polymer, complex, and system are introduced. The coordinate layer represents the three-dimensional coordinates of every atom in the system. The atom layer, as shown in @fig-multiplex, is the layer that represents the atoms and their bonds that construct objects in the monomer layer, e.g., an amino acid.\n\n![](images/fams-09-1150381-g009.jpg){#multiplex width=\"600\"}\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.2.0\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nAttaching package: 'data.table'\n\n\nThe following objects are masked from 'package:lubridate':\n\n    hour, isoweek, mday, minute, month, quarter, second, wday, week,\n    yday, year\n\n\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n\n\nThe following object is masked from 'package:purrr':\n\n    transpose\n\n\nLoading required package: usethis\n\nℹ Google's Terms of Service: <https://mapsplatform.google.com>\nℹ Please cite ggmap if you use it! Use `citation(\"ggmap\")` for details.\n\nAttaching package: 'igraph'\n\n\nThe following objects are masked from 'package:lubridate':\n\n    %--%, union\n\n\nThe following objects are masked from 'package:dplyr':\n\n    as_data_frame, groups, union\n\n\nThe following objects are masked from 'package:purrr':\n\n    compose, simplify\n\n\nThe following object is masked from 'package:tidyr':\n\n    crossing\n\n\nThe following object is masked from 'package:tibble':\n\n    as_data_frame\n\n\nThe following objects are masked from 'package:stats':\n\n    decompose, spectrum\n\n\nThe following object is masked from 'package:base':\n\n    union\n\n\n\nAttaching package: 'tidygraph'\n\n\nThe following object is masked from 'package:igraph':\n\n    groups\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\nLoading required package: statnet.common\n\n\nAttaching package: 'statnet.common'\n\n\nThe following objects are masked from 'package:base':\n\n    attr, order\n\n\nLoading required package: network\n\n\n'network' 1.18.1 (2023-01-24), part of the Statnet Project\n* 'news(package=\"network\")' for changes since last version\n* 'citation(\"network\")' for citation information\n* 'https://statnet.org' for help, support, and other information\n\n\n\nAttaching package: 'network'\n\n\nThe following objects are masked from 'package:igraph':\n\n    %c%, %s%, add.edges, add.vertices, delete.edges, delete.vertices,\n    get.edge.attribute, get.edges, get.vertex.attribute, is.bipartite,\n    is.directed, list.edge.attributes, list.vertex.attributes,\n    set.edge.attribute, set.vertex.attribute\n\n\nsna: Tools for Social Network Analysis\nVersion 2.7-1 created on 2023-01-24.\ncopyright (c) 2005, Carter T. Butts, University of California-Irvine\n For citation information, type citation(\"sna\").\n Type help(package=\"sna\") to get started.\n\n\n\nAttaching package: 'sna'\n\n\nThe following objects are masked from 'package:igraph':\n\n    betweenness, bonpow, closeness, components, degree, dyad.census,\n    evcent, hierarchy, is.connected, neighborhood, triad.census\n\n\nLoading required package: viridisLite\n\nRegistered S3 methods overwritten by 'bnlearn':\n  method   from\n  print.bn sna \n  plot.bn  sna \n\n\nAttaching package: 'bnlearn'\n\n\nThe following object is masked from 'package:sna':\n\n    degree\n\n\nThe following object is masked from 'package:tidygraph':\n\n    as.igraph\n\n\nThe following objects are masked from 'package:igraph':\n\n    as.igraph, compare, degree, subgraph\n\n\n\nAttaching package: 'xtable'\n\n\nThe following object is masked from 'package:ggdendro':\n\n    label\n\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\n\nAttaching package: 'kableExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\n\n\nAttaching package: 'tibbletime'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nLoading required package: gsubfn\n\nLoading required package: proto\n\nLoading required package: RSQLite\n\n------------------------------------------------------------------------------\n\nYou have loaded plyr after dplyr - this is likely to cause problems.\nIf you need functions from both plyr and dplyr, please load plyr first, then dplyr:\nlibrary(plyr); library(dplyr)\n\n------------------------------------------------------------------------------\n\n\nAttaching package: 'plyr'\n\n\nThe following object is masked from 'package:network':\n\n    is.discrete\n\n\nThe following objects are masked from 'package:tidygraph':\n\n    arrange, mutate, rename\n\n\nThe following objects are masked from 'package:dplyr':\n\n    arrange, count, desc, failwith, id, mutate, rename, summarise,\n    summarize\n\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\n\nNOTE: Either Arial Narrow or Roboto Condensed fonts are required to use these themes.\n\n      Please use hrbrthemes::import_roboto_condensed() to install Roboto Condensed and\n\n      if Arial Narrow is not on your system, please see https://bit.ly/arialnarrow\n\n\nAttaching package: 'pander'\n\n\nThe following object is masked from 'package:GGally':\n\n    wrap\n\n\n\nPlease cite as: \n\n\n Hlavac, Marek (2022). stargazer: Well-Formatted Regression and Summary Statistics Tables.\n\n R package version 5.2.3. https://CRAN.R-project.org/package=stargazer \n\n\nVersion:  1.38.6\nDate:     2022-04-06\nAuthor:   Philip Leifeld (University of Essex)\n\nConsider submitting praise using the praise or praise_interactive functions.\nPlease cite the JSS article in your publications -- see citation(\"texreg\").\n\n\nAttaching package: 'texreg'\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\n\nLearn more about sjPlot with 'browseVignettes(\"sjPlot\")'.\n\n\nAttaching package: 'sjmisc'\n\n\nThe following objects are masked from 'package:janitor':\n\n    remove_empty_cols, remove_empty_rows\n\n\nThe following object is masked from 'package:purrr':\n\n    is_empty\n\n\nThe following object is masked from 'package:tidyr':\n\n    replace_na\n\n\nThe following object is masked from 'package:tibble':\n\n    add_case\n\n\n\nAttaching package: 'sjlabelled'\n\n\nThe following object is masked from 'package:usethis':\n\n    tidy_labels\n\n\nThe following object is masked from 'package:forcats':\n\n    as_factor\n\n\nThe following object is masked from 'package:dplyr':\n\n    as_label\n\n\nThe following object is masked from 'package:ggplot2':\n\n    as_label\n\n\n\nAttaching package: 'rstatix'\n\n\nThe following objects are masked from 'package:plyr':\n\n    desc, mutate\n\n\nThe following object is masked from 'package:janitor':\n\n    make_clean_names\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n```\n:::\n:::\n\n\n# Data\n\nThe data consists of the mRNA and DNA sequences of 2 cancer patients where sequences areas of mutation have been selected and potential peptide candidates have been identified. Enzyme-linked immunospot (ELISpot) assays have been performed with the HLA alleles and peptides from both patients producing the values we wish to predict.\n\n## Data Overview\n\n### Data Dictionary\n\nThe produced data's attributes as listed in @tbl-data_dict_assays will give us the ability to create the network structures that represent the relationships between HLA alleles and peptides. This network structures will give us better insights and permit to apply analytical approaches to predict HLA-peptide interactions expressed as discretized class representing ranges of the numbers of matched blood mononuclear cells (PBMC's).\n\n\n::: {#tbl-data_dict_assays .cell tbl-cap='Data dict ELISpot assays' tbl-pos='h'}\n::: {.cell-output-display}\n\\begin{table}[H]\n\\centering\n\\resizebox{\\linewidth}{!}{\n\\begin{tabular}{lll}\n\\toprule\nvariable\\_name & variable\\_description & variable\\_options\\\\\n\\midrule\nELISPOT value & ELISPOT value & -25.83333333 to 1500\\\\\nNumber of peptides & Number of peptides & 1 to 3\\\\\nPatient & Patient & one to two\\\\\nPatient HLA & Patient HLA & A*11:01:01A*03:01:01B*15:32:01B*13:01:01C*07:02:01C*12:03:01 to A*11:01A*24:02B*15:01B*40:01C*01:02C*07:04\\\\\nPeptide's amino acids sequence & Peptide's amino acids sequence & AIKTSPKANK to YYVIINQVYRRKHQELQAMQM\\\\\n\\bottomrule\n\\end{tabular}}\n\\end{table}\n:::\n:::\n\n\n### Data Sample\n\nA sample from the data as visualized in @tbl-data_sample_assays, shows 10 values of the peptide's amino acids sequence with one letter code, the number of peptides per assay, the patients HLA's and the measured ELISpot value i.e. blood mononuclear cells (PBMC's).\n\n\n::: {#tbl-data_sample_assays .cell tbl-cap='Sample ELISpot assays' tbl-pos='h'}\n::: {.cell-output-display}\n\\begin{table}[H]\n\\centering\n\\resizebox{\\linewidth}{!}{\n\\begin{tabular}{rlrll}\n\\toprule\nNumber of peptides & Peptide's amino acids sequence & ELISPOT value & Patient HLA & Patient\\\\\n\\midrule\n1 & IPVAIKTSPK & 28.33333 & A*11:01:01A*03:01:01B*15:32:01B*13:01:01C*07:02:01C*12:03:01 & one\\\\\n1 & AIKTSPKANK & 77.66667 & A*11:01:01A*03:01:01B*15:32:01B*13:01:01C*07:02:01C*12:03:01 & one\\\\\n1 & KGLWIPEGEKVKIPVAIKTSPKANK & 123.00000 & A*11:01:01A*03:01:01B*15:32:01B*13:01:01C*07:02:01C*12:03:01 & one\\\\\n1 & IPEGEKVKIPVAIKTSPKANKEILD & 86.66667 & A*11:01:01A*03:01:01B*15:32:01B*13:01:01C*07:02:01C*12:03:01 & one\\\\\n1 & WIPEGEKVKIPVAIKTSPKANKEIL & 51.33333 & A*11:01:01A*03:01:01B*15:32:01B*13:01:01C*07:02:01C*12:03:01 & one\\\\\n\\addlinespace\n1 & LWIPEGEKVKIPVAIKTSPKANKEI & 89.33333 & A*11:01:01A*03:01:01B*15:32:01B*13:01:01C*07:02:01C*12:03:01 & one\\\\\n\\bottomrule\n\\end{tabular}}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n:::\n\n{{< pagebreak >}}\n\n\n\n### ELISpot value Distribution\n\nAs shown in @fig-elispot_values_hist, we wish to look at the distribution of the ELISpot values for both patients.The medians from both patients are different as well as the distribution of the values. The values of patient one are restricted to a smaller range and show an outlier in the upper quartile. In contrast patient two shows values distributed over a wider range, again with a wider distribution in the upper quartile.\n\nWe can conclude that the patients show different distributions of observed PBMC values, i.e. the PBMC values are patient specific.\n\n\n\n```\nWarning: Use of `pationsOneandTwoDf$ELISPOTvalue` is discouraged.\nℹ Use `ELISPOTvalue` instead.\n```\n\n```\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n```\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\nSaving 7 x 5 in image\n```\n\n{{< pagebreak >}}\n\n\n\n### Peptides nr. vs ELISpot Value\n\nIn @fig-elispot_values_violin, we graph a violin plot to analyze how the number of peptides in a system correlate with the PBMC values and specific patient. We see that patient two has systems with exclusively one peptide in contrast to patient one that has systems with one, two and three peptides. Patient one has sa high concentration of systems with only one peptide. The correlation between number of peptides and ELISPot values is not clear. Systems with one peptide seem to produce higher PBMC values in contrast to systems with multiple peptides. This conclusion should be take with caution since only patient one has systems with more than one peptide.\n\n\n\n```\nSaving 7 x 5 in image\n```\n\n{{< pagebreak >}}\n\n\n\n### Number of Amino acids vs ELISpot values\n\nIn @fig-charts_p_one, we analyze the distribution of ELISpot values in relation to the total number of Amino Acids originating from the peptides in a system. We look at these correlations for both patients individually and together. Here the difference between the patients is not so clear, we observe a pattern in both patients where the lower and the upper range of the number of patients correlate with a high ELISPot value. It is notisible that systems with 30 amino acids consistently produce PBMC values above 500 for patient two. We can conclude that systems with higher total number of amino acids in the peptides tend to produce higher ELISpot values.\n\n\n::: {#fig-charts_p_one .cell layout=\"[[45,-10,45],[100]]\"}\n\n```\nSaving 7 x 5 in image\nPicking joint bandwidth of 27.5\n\nSaving 7 x 5 in image\nPicking joint bandwidth of 169\n\nSaving 7 x 5 in image\nPicking joint bandwidth of 102\n```\n\nPatient vs Tot. nr. Amino acids\n:::\n\n{{< pagebreak >}}\n\n\n\n### Linear Model coefficient analysis\n\nIn order to better understand the potential influence of particular data attributes we apply a linear regression model. Analyzing the coefficients we can understand the predictors influence on the produced PBMC values.\n\nFrom the results shown in @tbl-lmodel, we can see that the total number of amino acids in a system have positive linear relationship with the produced PBMC's for patient one and negative for patient two. The performance of the model differs between the two patients and the same coefficients have different linear relationship on the produced PBMC for the two patients. Hence the relationship between these coefficients and the matched PBMC value is patient specivif. This observation indicates that tumor mutations and immune system response are not only tumor but also patient specific.\n\n\n::: {.cell}\n\n:::\n\n::: {#tbl-lmodel .cell tbl-cap='Linear Regression model comparison' tbl-pos='h'}\n\n```\nWarning: Model matrix is rank deficient. Parameters `Numberofpeptides` were not\n  estimable.\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"2\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">All patients</th>\n<th colspan=\"2\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">Patient 1.</th>\n<th colspan=\"2\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">Patient 2.</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Coeffcient</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">P-Value</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">P-Value</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col7\">P-Value</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Intercept</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">447.60</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.017</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">101.15</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.011</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">470.34</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\">0.067</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Tot.Nr. Amino Acids</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">4.64</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.544</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">3.22</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.139</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;2.11</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\">0.853</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Nr. of Peptides</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;210.97</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.061</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;64.66</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.006</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\"></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"2\">65</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"2\">25</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"2\">40</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> / R<sup>2</sup> adjusted</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"2\">0.055 / 0.025</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"2\">0.298 / 0.234</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"2\">0.001 / -0.025</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n::: {.cell}\n\n:::\n\n{{< pagebreak >}}\n\n\n\n# Generated Data Structure\n\nThe peptide, as illustrated in @fig-Peptide, is a short chain of amino acids (typically 2 to 50) linked by chemical bonds (called peptide bonds). The HLA cell-surface protein, as illustrated in @fig-HLA, is a chain of amino acids that is responsible for the regulation of the immune system. To understand HLA-peptide interactions we need to understand how the peptide is binding, as illustrated in @fig-Complex, to the HLA in the context of a complex.\n\n![Peptide](images/paste-77AA87FC.png \"Peptide\"){#fig-Peptide width=\"150\" fig.pos=\"h\"}\n\n![HLA-Protein](images/paste-AF204FE5.png \"HLA-Protein\"){#fig-HLA alt=\"HLA\" fig.pos=\"h\"}\n\n![Complex](images/paste-2CA8D23F.png \"Complex\"){#fig-Complex fig.pos=\"h\"}\n\n\n{{< pagebreak >}}\n\n\n\n## Multiplex Network\n\nThe HLA-peptide interaction is dependent of the chemical reactions of atoms belonging to amino acids that will fall close enough in 3-dimensional space. To understand and study the diverse types of relations or interactions that exist between the components we chose a network representation with a notion of layers.\n\nThis type of networks is called multiplex networks as shown in @fig-multiplex where a node corresponds to a \"physical object,\" while node-layer pairs are different instances of the same object. For instance a node could represent an online user, while node-layer pairs would represent different accounts of the same user in different online social networks; or a node could\n\n![Multiplex](images/paste-41374747.png \"Multiplex\"){#fig-multiplex fig-align=\"right\" width=\"150\" fig.pos=\"h\"}\n\nrepresent a social actor, while node-layer pairs would represent different social roles (friend, worker, family member) of the same social actor; or a node could stand for a location in a transportation network, while node-layer pairs would represent stations of different transportation modes (e.g., streets, highways, and subways).\n\nThe connection between nodes and node-layer pairs is given by the notion of supra-nodes: i.e., cliques in the supra-graph formed by node-layer pairs that are instances of the same object.\n\nTo correctly represent a physical object in the different layers of the multiplex we break down the peptides to amino acids and the amino acids to their smallest component atoms and their connections bonds. The layers coordinate, atom, monomer, polymer, complex and system are introduced.\n\n\n{{< pagebreak >}}\n\n\n\nThe **Atom layer**, as shown in @fig-MultiplexArchitecture, is the layer that represents the atoms and their bonds that construct objects in the monomer layer e.g., amino acid.\n\nThe **Monomer laye**r, as shown in @fig-MultiplexArchitecture, represents the objects of type monomer that is a molecule of any of a class of compounds, mostly organic, that can react with other molecules to form very large molecules, or polymers.\n\nThe **Polymer layer**, as shown in @fig-MultiplexArchitecture, represents the objects of type polymer. Polymer is any object of a class of natural or synthetic substances composed of very large molecules, called macromolecules, which are multiples of monomers.\n\nThe **Complex layer**, as shown in @fig-MultiplexArchitecture, represents polymers that form a complex by binding to each other e.g. peptide binds to a HLA to form a complex.\n\nThe **System layer** represents the totality of complexes that exist in an ELISpot assay and is representative of multiple HLA-peptide complexes. One system could be represented as shown in @fig-MultiplexArchitecture where we are omitting the coordinates layer.\n\n![Multiplex Architecture](images/paste-980BA7D9.png \"Multiplex Architecture\"){#fig-MultiplexArchitecture fig.pos=\"h\" width=\"450\"}\n\n\n{{< pagebreak >}}\n\n\n\n## Network Topological Attributes\n\nTo compare and predict systems interactions and behavior we will look at measures and metrics that these networks express. Calculating and assigning these metrics for every individual system permits us to create a dataset that can be used in statistical, machine and deep learning analysis approaches. Additionally, we apply deep learning on graphs on the individual systems to make predictions of their interactions in this case the ELISpot result.\n\n\n::: {.cell}\n\n:::\n\n\n### Size largest Component\n\nIn undirected networks typically exists large components that fill most of the network, while the rest of the network is divided into a lot of small disconnected components. The size of the largest connected component can be expressed by: $S=1-e^{-cS}$ introduced by Erdos and Renyi in 1958 where $c$ denotes mean degree or the average of in- and out-going edges.\\\n\\\nWe compute the size of the largest component $S$ of each system and and look at its distribution and correlation with the particular patient and the measured matched PBMC's i.e. ELISpot values.\n\n\\\nAs visualized in @fig-SizelargestComponent, even though the medians of both patients are close, the values of patient one are better distributed with a large portion in the lower quartile. Patient two shows a high concentration around the median and the upper quartile and an outlier in the upper whisker.\n\n\\\nWhen considering the $S$ values over all the systems, we observe a positive correlation with the matched PBMC's with statistical significance shown by a $p-value <0.10$.\\\nThis could mean that systems that create larger connected components, have a higher chance of producing a higher PBMC value. This is confirmed by the distribution of the PBMC values of patient two, showing overall significantly higher values than patient one, and a distribution of the size of the largest components that is concentrated around the median of 30 and the upper quartile.\\\nWhen looking at the individual patients, we observe that patient two shows inverse correlation, even though not significant, with the matched PBMC's. Patient one shows a positive correlation with matched PBMC's.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![Patient Matched PBMC's vs. Size largest Component](index_files/figure-html/fig-SizelargestComponent-1.png){#fig-SizelargestComponent fig-pos='h' width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n:::\n\n{{< pagebreak >}}\n\n\n\n### Avg. Spectral clustering\n\nA fast approach to separate a network in communities is by applying spectral modularity maximization by assigning a node to one of two groups communities. If we consider $s$ as a vector in n-dimensional space, that implies that the vector must point to one of the corners of the n-dimensional hypercube. By creating a relaxed method where $s$ is aloud to take any value of $|s|=\\sqrt{n}$ the form we arrive at a matrix notation $Bs=\\beta s$. Hense the optimal $s$ is on of the eigenvectors of the modularity matrix and $\\beta$ is the corresponding eigenvalue. We can find which eigenvector by applying $$Q=\\dfrac{n}{4m}\\beta$$ Since $s^Ts=n$ we can maximize the inner product $s^Tu=\\sum_is_iu_i$. The maximum is achieved when $s_iu_i$ is positive for all $i$, which occurs when $s_i$ has the same sign as $u_i$ for all $i$: $$s_i=\\begin{cases}\n+1, & \\text{if } u_i>0\\\\\n-1, & \\text{if }u_i<0\n\\end{cases}$$\n\nThis leads to a simple approach, we calculate the eigenvector of ton the modularity matrix corresponding to the highest eigenvalue and assign nodes ot communities according to the signs of the elements in this vector.\n\nWe slightly modify it by assigning zero to the nodes that correspond to negative eigenvalues instead of -1: $$s_i=\\begin{cases}\n+1, & \\text{if } u_i>0\\\\\n0, & \\text{if }u_i<0\n\\end{cases}$$ Then we calculate the average $\\dfrac{1}{n}\\sum_{s=1}^{n}s_i$ of the assigned values that produces a value between zero and one and is indicative of how balanced is the distribution of the nodes between two communities.\n\nIn @fig-Laplacianclustering we calculate the avg. spectral clustering for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC's i.e. ELISpot values.\n\nWe see that the distributions for both patients are quite similar. Patient two produces values that are skewed towards the lower quartile while patient one values are better distributed around the median. Even though combined data of both patients show a inverse Pearson correlation coefficient with the matched PBMC's, patient one shows a positive correlation with statistical significance indicated by a $p-value<0.05$.\n\nThis might indicate that there is a difference in the produced PMBC's between patients with similar avg. spectral clustering values. In other words the systems of individual patients react differently to a similar internal node distribution between two communities.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![Patient Matched PBMC's vs. Avg. Spectral clustering](index_files/figure-html/fig-Laplacianclustering-1.png){#fig-Laplacianclustering fig-pos='h' width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n:::\n\n{{< pagebreak >}}\n\n\n\n### Global Clustering Coefficient\n\nClustering coefficient is a measure of the degree to which vertices in a network tend to create tightly knit groups, closed triads: $$ C=\\dfrac{(\\text{number of closed paths of length two})}{(\\text{number of paths of length two})}$$ C=1 implies perfect transitivity,a networks whose components are all closed triads. C=0 implies no closed triads. Concretely we apply the Watts and Strogatz defined a clustering coefficient that quantifies the likelihood that two nodes that are connected to the same node are also connected to each other. degree to which vertices in a network tend to create tightly knit groups, closed triads: $$ C=\\dfrac{(\\text{number of triangles})*3}{(\\text{number of connected triples})}$$ Concretely we apply the following formula $$C=\\dfrac{1}{n}\\sum_{u=1}^{n}c_u$$ where $n$ is the number of nodes and $c_u$ is: $$c_u = \\frac{2 T(u)}{deg(u)(deg(u)-1)}$$ where $T(u)$ is the number of triangles through node $u$ and $deg(u)$ is the degree of $u$.\n\nIn @fig-GlobalClusteringCoeffiecient we calculate global clustering coefficient for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC's i.e. ELISpot values.\n\nWe see that the distributions for both patients are quite similar. Patient two produces values that are skewed towards the upper quartile while patient one values are better distributed around the median. Combined data of both patients shows a positive Pearson correlation coefficient,with statistical significance indicated by a $p-value<0.05$, with the matched PBMC's. Patient one and two show a similar positive correlation.\n\nThis observation can imply that systems with high clustering coefficient, i.e. systems where monomers, polymers and atoms that are connected to the same monomer, polymer or atom have a high likelihood to be connected to each other, will produce a higher number of matched PBMC's.\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n:::\n\n{{< pagebreak >}}\n\n\n\n### Transitivity\n\nThe fundamental type of relation between nodes in a network is \"connected by an edge.\" If the \"connected by an edge\" relation were transitive it would mean that if node u is connected to node v, and v is connected to w, then u is also connected to w. $$T = 3\\frac{\\#triangles}{\\#triads}$$ where \"triads\" are two edges with a shared vertex and triangles are loops of length three.\n\nIn @fig-Transitivity we calculate the transitivity for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC's i.e. ELISpot values.\n\nWe see that the distributions for both patients are quite similar. Patient one produces values that are skewed towards the lower quartile while patient two values are better distributed around the median. Combined data of both patients show a positive Pearson correlation coefficient,with no statistical significance, with the matched PBMC's. Patient one and two show a similar positive correlation.\n\nThis might confirm the observed correlation with the global clustering coefficient.\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n:::\n\n{{< pagebreak >}}\n\n\n\n### Average Degree\n\nThe average degree of a network:$$\\langle k \\rangle=2\\frac{\\text{number of edges}}{\\text{number of nodes}}$$ is related to the density of the network, where in a dense network the average degree grows linearly with the number of nodes, while in a sparse network it grows sub linearly.\n\nIn @fig-AverageDegree we calculate $\\langle k \\rangle$ for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC's i.e. ELISpot values.\n\nWe see that the distributions for both patients are some what similar. Patient one produces values that are skewed towards the lower quartile while patient two values are better distributed around the median. The median of patient one is significantly higher.\n\nCombined data of both patients show an inverse Pearson correlation coefficient, with no statistical significance, with the matched PBMC's. Patient two shows a similar positive correlation in contrast to patient one that shows a positive correlation.\n\nFrom these observations we could imply that impact of the density of the network on the matched PBMC's is patient specific.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![Patient Matched PBMC's vs. Average Degree](index_files/figure-html/fig-AverageDegree-1.png){#fig-AverageDegree fig-pos='h' width=672}\n:::\n:::\n\n{{< pagebreak >}}\n\n\n\n### Degree Centrality\n\nA large volume of work is dedicated to centrality. The question which are the most important vertices in or central nodes in a network. There are many possible definitions of importance and consequently many centrality measures. Degree, the number of incoming and outgoing edges a node has, is sometimes called degree centrality to emphasize its use as a centrality measure. Useful though it is quite a crude measure as it awards a node one centrality point for every neighbor it has. But not all neighbors are necessarily equivalent.\n\nIn @fig-DegreeCentrality we calculate the degree centrality for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC's i.e. ELISpot values.\n\nWe see that the distributions for both patients are different. Patient one produces values that are mostly skewed towards the lower quartile while patient two are skewed towards the upper quartile. The median of patient one is significantly higher.\n\nCombined data of both patients show a positive Pearson correlation coefficient with a statistical significance indicated by a $p-value<0.05$, with the matched PBMC's. Patient two shows a similar positive correlation in contrast to patient one that shows a correlation near to zero.\n\nFrom these observations we could imply that impact of high number of incoming and outgoing edges from the vertices in the system have a positive impact on the matched PBMC's. There is however a patient specific aspect in the magnitude of the positive impact.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![Patient Matched PBMC's vs. Degree Centrality](index_files/figure-html/fig-DegreeCentrality-1.png){#fig-DegreeCentrality fig-pos='h' width=672}\n:::\n:::\n\n{{< pagebreak >}}\n\n\n\n### Average Core Hubs\n\nAverage core hubs is a measure of the average of the degrees of the top-100 hubs in a system:$$\\dfrac{1}{n}\\sum_{i=1}^{100}k_i$$ where $k$ is the degree of vertice i.\n\nIn @fig-AverageCoreHubs we calculate the average core hubs for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC's i.e. ELISpot values.\n\nWe see that the distributions for both patients are different. Patient one produces values that are mostly skewed towards the lower quartile while patient two skewed towards the upper quartile. The median of patient one is significantly higher.\n\nCombined data of both patients show a positive Pearson correlation coefficient with statistical significance indicated by a $p-value<0.01$, with the matched PBMC's. Patient two shows a similar positive correlation in contrast to patient one that shows a correlation near to zero.\n\nFrom these observations we could imply that impact of high number of incoming and outgoing edges from the vertices in the system have a positive impact on the matched PBMC's. There is however a patient specific aspect in the magnitude of the positive impact. This observation agrees with the observations of Degree Centrality and its correlation with the matched PBMC values.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![Patient Matched PBMC's vs. Average Core Hubs](index_files/figure-html/fig-AverageCoreHubs-1.png){#fig-AverageCoreHubs fig-pos='h' width=672}\n:::\n:::\n\n{{< pagebreak >}}\n\n\n\n### Density\n\nDensity of a graph is the ratio between the edges present in a graph and the maximum number of edges that the graph can contain. Conceptually, it provides an idea of how dense a graph is in terms of edge connectivity. $$ d = \\frac{m}{n(n-1)}$$ where `n` is the number of nodes and `m` is the number of edges in a graph `G`.\n\nIn @fig-Density we calculate the density for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC's i.e. ELISpot values.\n\nWe see that the distributions for both patients are different. Patient one produces values that are mostly skewed towards the lower quartile while patient's two are skewed towards the upper quartile. The median of patient one is significantly higher.\n\nCombined data of both patients show a positive Pearson correlation coefficient with statistical significance indicated by a $p-value<0.01$, with the matched PBMC's. Patient two shows a similar positive correlation in contrast to patient one that shows a correlation near to zero.\n\nFrom these observations we could imply that a high number of incoming and outgoing edges from the vertices in the system have a positive impact on the matched PBMC's. There is however a patient specific aspect in the magnitude of the positive impact. This observation agrees with the observations of Degree Centrality and Average Core Hubs.As the measures, Density,Degree Centrality and Average Core Hubs, overlap it make sense to select the one with the highest correlation and statistical significance i.e. Average Core Hubs.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![Patient Matched PBMC's vs. Density](index_files/figure-html/fig-Density-1.png){#fig-Density fig-pos='h' width=672}\n:::\n:::\n\n{{< pagebreak >}}\n\n\n````{=html}\n<!--### Vectors\n\nSome text @fig-Vectors\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![Patient Matched PBMC's vs. Vectors](index_files/figure-html/fig-Vectors-1.png){#fig-Vectors fig-pos='h' width=672}\n:::\n:::\n\n\n{{< pagebreak >}}-->\n````\n\n### Betweenness Centrality\n\nBetweenness Centrality measures the importance of a node based on the number of paths between two other nodes that pass through it. Betweenness Centrality is a guide to the influence nodes have over the flow of information, energy between others. Betweenness Centrality $x_i$ is given by $$x_i=\\sum_{st}n^{i}_{st}$$ where $n^{i}_{st}$ is the node $i$ that lies on the shortest path from vertice $s$ to $t$.\n\nConcretely we average the betweennes centrality $$ \\langle x\\rangle=\\dfrac{1}{n}\\sum_{i=1}^{n}x_i$$\n\nIn @fig-BetweennessCentrality we calculate the Betweenness Centrality for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC's i.e. ELISpot values.\n\nWe see that the distributions for both patients are different. Patient one produces values that are mostly skewed towards the lower quartile while patient's two are skewed towards the upper quartile. The median of patient one is significantly higher.\n\nCombined data of both patients show a positive Pearson correlation coefficient with statistical significance indicated by a $p-value<0.01$, with the matched PBMC's. Patient two shows a similar positive correlation in contrast to patient one that shows a correlation near to zero.\n\nFrom these observations we could imply that impact of high number nodes in a system that are on the path between other nodes has a positive impact on the matched PBMC's. There is however a patient specific aspect in the magnitude of the positive impact.\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![Patient Matched PBMC's vs. Average Betweenness Centrality](index_files/figure-html/fig-BetweennessCentrality-1.png){#fig-BetweennessCentrality fig-pos='h' width=672}\n:::\n:::\n\n{{< pagebreak >}}\n\n### Closeness Centrality\n\nCloseness centrality of a node `u` is the reciprocal of the average shortest path distance to `u` over all `n-1` reachable nodes.\n\n$$C(u) = \\frac{n - 1}{\\sum_{v=1}^{n-1} d(v, u)}$$,\n\nwhere `d(v, u)` is the shortest-path distance between `v` and `u`,and `n` is the number of nodes that can reach `u`. Concretely we average the betweennes centrality $$ \\langle c\\rangle=\\dfrac{1}{n}\\sum_{u=1}^{n}c(u)$$\n\nIn @fig-ClosenessCentrality we calculate the Betweenness Centrality for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC's i.e. ELISpot values.\n\nWe see that the distributions for both patients are different. Patient one produces values that are mostly skewed towards the lower quartile while patient two are evenly distributed. The median of patient one is significantly higher.\n\nCombined data of both patients show a positive Pearson correlation coefficient with statistical significance indicated by a $p-value<0.05$, with the matched PBMC's. Patient one and two shows a similar positive correlation.\n\nFrom these observations we could imply that,the impact of high number nodes in a system with a high number of shortest distances to all other nodes, has a positive impact on the matched PBMC's.\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![Patient Matched PBMC's vs. Closeness Centrality](index_files/figure-html/fig-ClosenessCentrality-1.png){#fig-ClosenessCentrality fig-pos='h' width=672}\n:::\n:::\n\n{{< pagebreak >}}\n\n### Degree Pearson Correlation Coefficient\n\nMeasures the degree assortativity of a network i.e. the similarity of connections in the graph with respect to the node degree.It varies between −1 ≤ r ≤ 1: For r \\< 0 the network is assortative, for r = 0 the network is neutral and for r \\> 0 the network is disassortative.\n\nIn @fig-DegreePearsonCorrelationCoefficient we calculate the Degree Pearson correlation Coefficient for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC's i.e. ELISpot values.\n\nWe see that the distributions for both patients are different. Patient one and two produce values that are mostly skewed towards the upper quartile but there is a significant difference in their medians.\n\nCombined data of both patients show a positive Pearson correlation coefficient with statistical significance indicated by a $p-value<0.05$, with the matched PBMC's. Patient one and two show a similar positive correlation.\n\nFrom these observations we could imply that,a high number similar connections between nodes in a system e.g. monomers,polymers,atoms has a positive impact on the matched PBMC's.\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![Patient Matched PBMC's vs. Degree Pearson Correlation Coefficient](index_files/figure-html/fig-DegreePearsonCorrelationCoefficient-1.png){#fig-DegreePearsonCorrelationCoefficient fig-pos='h' width=672}\n:::\n:::\n\n{{< pagebreak >}}\n\n### Eigen Vector Centrality\n\nIn many circumstances a node's importance in a network is increased by having connections with other nodes that are themselves important. Eigenvector centrality is an extension of degree centrality that takes this factor into account. Eigenvector centrality awards to a node a number of points proportional to the centrality scores of its neighbors. The eigenvector centrality $x_i$ of node $i$ is defined to be proportional to the sum of the centralities of i's neighbors. The eigenvector centrality $x_i$ of node i is defined to be proportional to the sum of the centralities of i's neighbors\n\n$$\nx_i=k^{-1} \\sum_{\\text{nodes j}\\\\ \\text{ neighbours of i}}x_j \n$$ In matrix notation $$x=k^{-1} Ax\\\\ Ax=kx$$ where x is the vector with elements equal to the centrality scores x_i and k is a constant. In other words, x is an eigenvector of the adjacency matrix.\n\nIn @fig-EigenVectorCentrality we calculate the average Eigen Vector Centrality for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC's i.e. ELISpot values.\n\nWe see that the distributions for both patients are very similar. Patient one and two produce values that are mostly skewed towards the upper quartile with patient two having a longer tail.\n\nCombined data of both patients show a positive Pearson correlation coefficient with no statistical significance , with the matched PBMC's. However patient two shows an inverse correlation in contrast to positive correlation of patient one.\n\nFrom these observations we could imply that importance of this measure towards the impact on the matched PBMC's is not significant and it is patient specific.\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![Patient Matched PBMC's vs. Eigen Vector Centrality](index_files/figure-html/fig-EigenVectorCentrality-1.png){#fig-EigenVectorCentrality fig-pos='h' width=672}\n:::\n:::\n\n{{< pagebreak >}}\n\n### Page Rank Centrality\n\nIf a node with high Katz centrality has edges pointing to many others, then all of those others also get high centrality. A high-centrality node pointing to one million others gives all one million of them high centrality. One could argue that this is not always appropriate. In many cases it means less if a node is only one among many that are pointed to. The centrality gained by virtue of receiving an edge from a prestigious node is diluted by being shared with so many others.\n\nWe can derive the following variant of Katz centrality in which the centrality we derive from the network neighbors is proportional to their centrality divided by their out-degree. $$x_i=α\\sum_jA_{ij}\\frac{x_j}{k_j^{out}} +β$$\n\nIn @fig-PageRankCentrality\n\nwe calculate the average Page Rank Centrality for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC's i.e. ELISpot values.\n\nWe see that the distributions for both patients are very different. Patient one and two produce similar medians but patient one distribution is skewed toward the lower quartile and patient two toward the higher quartile.\n\nCombined data of both patients show a positive Pearson correlation coefficient with statistical significance shown by a $p-value<0.05$, with the matched PBMC's. Patient two has similar correlation.\n\nFrom these observations we could imply that systems with a high number of nodes that have a high centrality based on connections from nodes that on their turn have high centrality has a positive influence on the produced PMBC's. However this influence seems to be patient specific.\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![Patient Matched PBMC's vs. Page Rank Centrality](index_files/figure-html/fig-PageRankCentrality-1.png){#fig-PageRankCentrality fig-pos='h' width=672}\n:::\n:::\n\n{{< pagebreak >}}\n\n### Attribute Assortativity Coefficient Source\n\nAssortativity measures the similarity of connections in the graph with respect to the attribute source. In the generated multiplex structure the attribute \"source\" refers to the unique id of the node the edge originates from.\n\nIn @fig-AttributeAssortativityCoefficientSource we calculate the average Attribute Assortativity Coefficient for attribute Source for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC's i.e. ELISpot values.\n\nWe see that the distributions for both patients are very different. Patient one and two produce similar medians but patient one distribution is skewed toward the upper quartile and patient two toward the lower quartile.\n\nCombined data of both patients show a inverse Pearson correlation coefficient with statistical significance shown by a $p-value<0.05$, with the matched PBMC's. Patient one and two have similar correlation.\n\nFrom these observations we could imply that systems with a more diverse unique node distribution have a higher likelihood to produce more PMBC's.\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![Patient Matched PBMC's vs. Attribute Assortativity Coefficient Source](index_files/figure-html/fig-AttributeAssortativityCoefficientSource-1.png){#fig-AttributeAssortativityCoefficientSource fig-pos='h' width=672}\n:::\n:::\n\n{{< pagebreak >}}\n\n### Causality Graph\n\nA Bayesian network is probabilistic model that represents the variables and their conditional dependencies as directed acyclic graph (DAG). In a DAG variables are represented as vertices and conditiononal dependencies as edges. Vertices that are not connected represent conditionally independent variables. Each node is associated with a probability function that takes in, a particular set of values for the node's parent variables, and gives the probability, or probability distribution, of the variable represented by the node.\n\nAs shown in @fig-causality, we apply a structure learning algorithm to the data in order to learn the structure of the directed acyclic graph (DAG) from the data. Concretely we apply Incremental Association (IAMB) algorithm, based on the Markov blanket detection algorithm of the same name, which is based on a two-phase selection scheme (a forward selection followed by an attempt to remove false positives).\n\nAnalyzing the DAG we see that the matched PBMC, vectors,Average core hubs, Attribute Assortativity Coefficient Source,Size largest component, Eigen vector Centrality and closeness centrality are conditionally dependent on the patient. This observation confirms observations made the correlation analysis. This indicates that system structures have patient specific attributes and their matched PBMC's are as well patient specific.\n\n::: {.cell}\n\n:::\n\n![](images/fig-causality.jpg){#fig-causality fig-align=\"center\" width=\"300\"}\n\n{{< pagebreak >}}\n\n### Multivariate analysis of variance\n\nMultivariate analysis of variance (MANOVA) is a statistical procedure for comparison of multivariate sample means. It is often used when there are two or more dependent variables and we wish to perform regression analysis and analysis of variance for them by one or more factor variables or covariates.\n\nIn our case we wish to determine which network topology attributes are highly significantly different among patients.\n\nFrom the results shown in the following table, we see that Matched PBMC,Average Core hubs, Average Betweenness Centrality have a high statistical significance with $p-value<0.001$.\n\nCloseness Centrality,Degree Pearson Correlation Coefficient, Page Rank Centrality,Attribute Assortativity Coefficient Source with $p-value<0.01$\n\nSize largest Component, Response Degree Centrality,Density statistical sigificance with $p-value<0.05$\n\nFrom this analysis we can conclude that there are indications that the produced PBMC values are statistically significantly different per patient together with a number of topological network attributes. This is agrees with the observations in the distributions and the correlations with the produced PDBC's.\n\n::: {.cell tbl-pos='h' tbl-cap='MANOVA network topology attributes'}\n\n  * ** Response Size largest Component**:\n\n    ----------------------------------------------------------------\n        &nbsp;       Df    Sum Sq     Mean Sq    F value    Pr(>F)\n    --------------- ---- ---------- ----------- --------- ----------\n      **Patient**    1    0.002939   0.002939     14.29    0.000373\n\n     **Residuals**   58   0.01193    0.0002058     NA         NA\n    ----------------------------------------------------------------\n\n  * ** Response Laplacian clustering**:\n\n    ---------------------------------------------------------------\n        &nbsp;       Df    Sum Sq      Mean Sq    F value   Pr(>F)\n    --------------- ---- ----------- ----------- --------- --------\n      **Patient**    1    7.603e-07   7.603e-07    1.128    0.2927\n\n     **Residuals**   58   3.91e-05    6.742e-07     NA        NA\n    ---------------------------------------------------------------\n\n  * ** Response Global Clustering Coeffiecient**:\n\n    ---------------------------------------------------------------\n        &nbsp;       Df    Sum Sq      Mean Sq    F value   Pr(>F)\n    --------------- ---- ----------- ----------- --------- --------\n      **Patient**    1    0.0002044   0.0002044   0.6412    0.4265\n\n     **Residuals**   58    0.01849    0.0003187     NA        NA\n    ---------------------------------------------------------------\n\n  * ** Response Transitivity**:\n\n    --------------------------------------------------------------\n        &nbsp;       Df   Sum Sq    Mean Sq    F value    Pr(>F)\n    --------------- ---- --------- ---------- --------- ----------\n      **Patient**    1    0.01722   0.01722     7.502    0.008175\n\n     **Residuals**   58   0.1331    0.002296     NA         NA\n    --------------------------------------------------------------\n\n  * ** Response Average degree**:\n\n    ---------------------------------------------------------------\n        &nbsp;       Df    Sum Sq      Mean Sq    F value   Pr(>F)\n    --------------- ---- ----------- ----------- --------- --------\n      **Patient**    1    5.252e-05   5.252e-05   0.05573   0.8142\n\n     **Residuals**   58    0.05466    0.0009424     NA        NA\n    ---------------------------------------------------------------\n\n  * ** Response Average Clustering**:\n\n    ----------------------------------------------------------------\n        &nbsp;       Df    Sum Sq      Mean Sq    F value   Pr(>F)\n    --------------- ---- ----------- ----------- --------- ---------\n      **Patient**    1    6.182e-06   6.182e-06    3.257    0.07631\n\n     **Residuals**   58   0.0001101   1.898e-06     NA        NA\n    ----------------------------------------------------------------\n\n  * ** Response Degree Centrality**:\n\n    ---------------------------------------------------------------\n        &nbsp;       Df    Sum Sq      Mean Sq    F value   Pr(>F)\n    --------------- ---- ----------- ----------- --------- --------\n      **Patient**    1    8.194e-06   8.194e-06   0.1305    0.7192\n\n     **Residuals**   58   0.003641    6.278e-05     NA        NA\n    ---------------------------------------------------------------\n\n  * ** Response Average Core hubs**:\n\n    ---------------------------------------------------------------\n        &nbsp;       Df    Sum Sq      Mean Sq    F value   Pr(>F)\n    --------------- ---- ----------- ----------- --------- --------\n      **Patient**    1    0.0002156   0.0002156   0.6706    0.4162\n\n     **Residuals**   58    0.01865    0.0003216     NA        NA\n    ---------------------------------------------------------------\n\n  * ** Response Density**:\n\n    ----------------------------------------------------------------\n        &nbsp;       Df    Sum Sq      Mean Sq    F value   Pr(>F)\n    --------------- ---- ----------- ----------- --------- ---------\n      **Patient**    1    6.182e-06   6.182e-06    3.257    0.07631\n\n     **Residuals**   58   0.0001101   1.898e-06     NA        NA\n    ----------------------------------------------------------------\n\n  * ** Response Vectors**:\n\n    -----------------------------------------------------------------\n        &nbsp;       Df    Sum Sq      Mean Sq    F value    Pr(>F)\n    --------------- ---- ----------- ----------- --------- ----------\n      **Patient**    1    3.963e-07   3.963e-07    10.16    0.002309\n\n     **Residuals**   58   2.261e-06   3.899e-08     NA         NA\n    -----------------------------------------------------------------\n\n  * ** Response Average Betweenness Centrality**:\n\n    ---------------------------------------------------------------\n        &nbsp;       Df   Sum Sq    Mean Sq    F value    Pr(>F)\n    --------------- ---- --------- ---------- --------- -----------\n      **Patient**    1    0.07884   0.07884     12.39    0.0008457\n\n     **Residuals**   58   0.3689    0.006361     NA         NA\n    ---------------------------------------------------------------\n\n  * ** Response Closeness Centrality**:\n\n    -----------------------------------------------------------------\n        &nbsp;       Df    Sum Sq      Mean Sq    F value    Pr(>F)\n    --------------- ---- ----------- ----------- --------- ----------\n      **Patient**    1    3.551e-07   3.551e-07    10.16    0.002309\n\n     **Residuals**   58   2.026e-06   3.493e-08     NA         NA\n    -----------------------------------------------------------------\n\n  * ** Response Degree Pearson Correlation Coefficient**:\n\n    ----------------------------------------------------------\n        &nbsp;       Df   Sum Sq   Mean Sq   F value   Pr(>F)\n    --------------- ---- -------- --------- --------- --------\n      **Patient**    1     6316     6316      1.078    0.3036\n\n     **Residuals**   58   339962    5861       NA        NA\n    ----------------------------------------------------------\n\n  * ** Response Eigenvector Centrality**:\n\n    ------------------------------------------------------------------\n        &nbsp;       Df    Sum Sq      Mean Sq    F value    Pr(>F)\n    --------------- ---- ----------- ----------- --------- -----------\n      **Patient**    1    1.618e-08   1.618e-08    13.68    0.0004833\n\n     **Residuals**   58   6.86e-08    1.183e-09     NA         NA\n    ------------------------------------------------------------------\n\n  * ** Response Page Rank Centrality**:\n\n    ----------------------------------------------------------------\n        &nbsp;       Df    Sum Sq     Mean Sq    F value    Pr(>F)\n    --------------- ---- ---------- ----------- --------- ----------\n      **Patient**    1    0.001067   0.001067     11.91    0.001046\n\n     **Residuals**   58   0.005193   8.954e-05     NA         NA\n    ----------------------------------------------------------------\n\n  * ** Response Attribute Assortativity Coefficient Type**:\n\n    -----------------------------------------------------------------\n        &nbsp;       Df    Sum Sq      Mean Sq    F value    Pr(>F)\n    --------------- ---- ----------- ----------- --------- ----------\n      **Patient**    1    0.0005459   0.0005459    7.848    0.006903\n\n     **Residuals**   58   0.004034    6.955e-05     NA         NA\n    -----------------------------------------------------------------\n\n  * ** Response Attribute Assortativity Coefficient Source**:\n\n    ---------------------------------------------------------------\n        &nbsp;       Df    Sum Sq      Mean Sq    F value   Pr(>F)\n    --------------- ---- ----------- ----------- --------- --------\n      **Patient**    1    8.284e-08   8.284e-08   0.04645   0.8301\n\n     **Residuals**   58   0.0001034   1.783e-06     NA        NA\n    ---------------------------------------------------------------\n\n  * ** Response Matched PBMC**:\n\n    -----------------------------------------------------------------\n        &nbsp;       Df    Sum Sq      Mean Sq    F value    Pr(>F)\n    --------------- ---- ----------- ----------- --------- ----------\n      **Patient**    1    2.488e-08   2.488e-08    10.01    0.002478\n\n     **Residuals**   58   1.442e-07   2.486e-09     NA         NA\n    -----------------------------------------------------------------\n\n\n<!-- end of list -->\n\n\n\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com\n% Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n\\begin{table}[!htbp] \\centering \n  \\caption{} \n  \\label{} \n\\begin{tabular}{@{\\extracolsep{5pt}}lccccc} \n\\\\[-1.8ex]\\hline \n\\hline \\\\[-1.8ex] \nStatistic & \\multicolumn{1}{c}{N} & \\multicolumn{1}{c}{Mean} & \\multicolumn{1}{c}{St. Dev.} & \\multicolumn{1}{c}{Min} & \\multicolumn{1}{c}{Max} \\\\ \n\\hline \\\\[-1.8ex] \nDf & 2 & 29.500 & 40.305 & 1 & 58 \\\\ \nSum Sq & 2 & 0.007 & 0.006 & 0.003 & 0.012 \\\\ \nMean Sq & 2 & 0.002 & 0.002 & 0.0002 & 0.003 \\\\ \nF value & 1 & 14.286 &  & 14.286 & 14.286 \\\\ \nPr(\\textgreater F) & 1 & 0.0004 &  & 0.0004 & 0.0004 \\\\ \n\\hline \\\\[-1.8ex] \n\\end{tabular} \n\\end{table} \n\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com\n% Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n\\begin{table}[!htbp] \\centering \n  \\caption{} \n  \\label{} \n\\begin{tabular}{@{\\extracolsep{5pt}}lccccc} \n\\\\[-1.8ex]\\hline \n\\hline \\\\[-1.8ex] \nStatistic & \\multicolumn{1}{c}{N} & \\multicolumn{1}{c}{Mean} & \\multicolumn{1}{c}{St. Dev.} & \\multicolumn{1}{c}{Min} & \\multicolumn{1}{c}{Max} \\\\ \n\\hline \\\\[-1.8ex] \nDf & 2 & 29.500 & 40.305 & 1 & 58 \\\\ \nSum Sq & 2 & 0.00002 & 0.00003 & 0.00000 & 0.00004 \\\\ \nMean Sq & 2 & 0.00000 & 0.00000 & 0.00000 & 0.00000 \\\\ \nF value & 1 & 1.128 &  & 1.128 & 1.128 \\\\ \nPr(\\textgreater F) & 1 & 0.293 &  & 0.293 & 0.293 \\\\ \n\\hline \\\\[-1.8ex] \n\\end{tabular} \n\\end{table} \n\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com\n% Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n\\begin{table}[!htbp] \\centering \n  \\caption{} \n  \\label{} \n\\begin{tabular}{@{\\extracolsep{5pt}}lccccc} \n\\\\[-1.8ex]\\hline \n\\hline \\\\[-1.8ex] \nStatistic & \\multicolumn{1}{c}{N} & \\multicolumn{1}{c}{Mean} & \\multicolumn{1}{c}{St. Dev.} & \\multicolumn{1}{c}{Min} & \\multicolumn{1}{c}{Max} \\\\ \n\\hline \\\\[-1.8ex] \nDf & 2 & 29.500 & 40.305 & 1 & 58 \\\\ \nSum Sq & 2 & 0.009 & 0.013 & 0.0002 & 0.018 \\\\ \nMean Sq & 2 & 0.0003 & 0.0001 & 0.0002 & 0.0003 \\\\ \nF value & 1 & 0.641 &  & 0.641 & 0.641 \\\\ \nPr(\\textgreater F) & 1 & 0.427 &  & 0.427 & 0.427 \\\\ \n\\hline \\\\[-1.8ex] \n\\end{tabular} \n\\end{table} \n\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com\n% Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n\\begin{table}[!htbp] \\centering \n  \\caption{} \n  \\label{} \n\\begin{tabular}{@{\\extracolsep{5pt}}lccccc} \n\\\\[-1.8ex]\\hline \n\\hline \\\\[-1.8ex] \nStatistic & \\multicolumn{1}{c}{N} & \\multicolumn{1}{c}{Mean} & \\multicolumn{1}{c}{St. Dev.} & \\multicolumn{1}{c}{Min} & \\multicolumn{1}{c}{Max} \\\\ \n\\hline \\\\[-1.8ex] \nDf & 2 & 29.500 & 40.305 & 1 & 58 \\\\ \nSum Sq & 2 & 0.075 & 0.082 & 0.017 & 0.133 \\\\ \nMean Sq & 2 & 0.010 & 0.011 & 0.002 & 0.017 \\\\ \nF value & 1 & 7.502 &  & 7.502 & 7.502 \\\\ \nPr(\\textgreater F) & 1 & 0.008 &  & 0.008 & 0.008 \\\\ \n\\hline \\\\[-1.8ex] \n\\end{tabular} \n\\end{table} \n\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com\n% Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n\\begin{table}[!htbp] \\centering \n  \\caption{} \n  \\label{} \n\\begin{tabular}{@{\\extracolsep{5pt}}lccccc} \n\\\\[-1.8ex]\\hline \n\\hline \\\\[-1.8ex] \nStatistic & \\multicolumn{1}{c}{N} & \\multicolumn{1}{c}{Mean} & \\multicolumn{1}{c}{St. Dev.} & \\multicolumn{1}{c}{Min} & \\multicolumn{1}{c}{Max} \\\\ \n\\hline \\\\[-1.8ex] \nDf & 2 & 29.500 & 40.305 & 1 & 58 \\\\ \nSum Sq & 2 & 0.027 & 0.039 & 0.0001 & 0.055 \\\\ \nMean Sq & 2 & 0.0005 & 0.001 & 0.0001 & 0.001 \\\\ \nF value & 1 & 0.056 &  & 0.056 & 0.056 \\\\ \nPr(\\textgreater F) & 1 & 0.814 &  & 0.814 & 0.814 \\\\ \n\\hline \\\\[-1.8ex] \n\\end{tabular} \n\\end{table} \n\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com\n% Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n\\begin{table}[!htbp] \\centering \n  \\caption{} \n  \\label{} \n\\begin{tabular}{@{\\extracolsep{5pt}}lccccc} \n\\\\[-1.8ex]\\hline \n\\hline \\\\[-1.8ex] \nStatistic & \\multicolumn{1}{c}{N} & \\multicolumn{1}{c}{Mean} & \\multicolumn{1}{c}{St. Dev.} & \\multicolumn{1}{c}{Min} & \\multicolumn{1}{c}{Max} \\\\ \n\\hline \\\\[-1.8ex] \nDf & 2 & 29.500 & 40.305 & 1 & 58 \\\\ \nSum Sq & 2 & 0.0001 & 0.0001 & 0.00001 & 0.0001 \\\\ \nMean Sq & 2 & 0.00000 & 0.00000 & 0.00000 & 0.00001 \\\\ \nF value & 1 & 3.257 &  & 3.257 & 3.257 \\\\ \nPr(\\textgreater F) & 1 & 0.076 &  & 0.076 & 0.076 \\\\ \n\\hline \\\\[-1.8ex] \n\\end{tabular} \n\\end{table} \n\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com\n% Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n\\begin{table}[!htbp] \\centering \n  \\caption{} \n  \\label{} \n\\begin{tabular}{@{\\extracolsep{5pt}}lccccc} \n\\\\[-1.8ex]\\hline \n\\hline \\\\[-1.8ex] \nStatistic & \\multicolumn{1}{c}{N} & \\multicolumn{1}{c}{Mean} & \\multicolumn{1}{c}{St. Dev.} & \\multicolumn{1}{c}{Min} & \\multicolumn{1}{c}{Max} \\\\ \n\\hline \\\\[-1.8ex] \nDf & 2 & 29.500 & 40.305 & 1 & 58 \\\\ \nSum Sq & 2 & 0.002 & 0.003 & 0.00001 & 0.004 \\\\ \nMean Sq & 2 & 0.00004 & 0.00004 & 0.00001 & 0.0001 \\\\ \nF value & 1 & 0.131 &  & 0.131 & 0.131 \\\\ \nPr(\\textgreater F) & 1 & 0.719 &  & 0.719 & 0.719 \\\\ \n\\hline \\\\[-1.8ex] \n\\end{tabular} \n\\end{table} \n\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com\n% Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n\\begin{table}[!htbp] \\centering \n  \\caption{} \n  \\label{} \n\\begin{tabular}{@{\\extracolsep{5pt}}lccccc} \n\\\\[-1.8ex]\\hline \n\\hline \\\\[-1.8ex] \nStatistic & \\multicolumn{1}{c}{N} & \\multicolumn{1}{c}{Mean} & \\multicolumn{1}{c}{St. Dev.} & \\multicolumn{1}{c}{Min} & \\multicolumn{1}{c}{Max} \\\\ \n\\hline \\\\[-1.8ex] \nDf & 2 & 29.500 & 40.305 & 1 & 58 \\\\ \nSum Sq & 2 & 0.009 & 0.013 & 0.0002 & 0.019 \\\\ \nMean Sq & 2 & 0.0003 & 0.0001 & 0.0002 & 0.0003 \\\\ \nF value & 1 & 0.671 &  & 0.671 & 0.671 \\\\ \nPr(\\textgreater F) & 1 & 0.416 &  & 0.416 & 0.416 \\\\ \n\\hline \\\\[-1.8ex] \n\\end{tabular} \n\\end{table} \n\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com\n% Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n\\begin{table}[!htbp] \\centering \n  \\caption{} \n  \\label{} \n\\begin{tabular}{@{\\extracolsep{5pt}}lccccc} \n\\\\[-1.8ex]\\hline \n\\hline \\\\[-1.8ex] \nStatistic & \\multicolumn{1}{c}{N} & \\multicolumn{1}{c}{Mean} & \\multicolumn{1}{c}{St. Dev.} & \\multicolumn{1}{c}{Min} & \\multicolumn{1}{c}{Max} \\\\ \n\\hline \\\\[-1.8ex] \nDf & 2 & 29.500 & 40.305 & 1 & 58 \\\\ \nSum Sq & 2 & 0.0001 & 0.0001 & 0.00001 & 0.0001 \\\\ \nMean Sq & 2 & 0.00000 & 0.00000 & 0.00000 & 0.00001 \\\\ \nF value & 1 & 3.257 &  & 3.257 & 3.257 \\\\ \nPr(\\textgreater F) & 1 & 0.076 &  & 0.076 & 0.076 \\\\ \n\\hline \\\\[-1.8ex] \n\\end{tabular} \n\\end{table} \n\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com\n% Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n\\begin{table}[!htbp] \\centering \n  \\caption{} \n  \\label{} \n\\begin{tabular}{@{\\extracolsep{5pt}}lccccc} \n\\\\[-1.8ex]\\hline \n\\hline \\\\[-1.8ex] \nStatistic & \\multicolumn{1}{c}{N} & \\multicolumn{1}{c}{Mean} & \\multicolumn{1}{c}{St. Dev.} & \\multicolumn{1}{c}{Min} & \\multicolumn{1}{c}{Max} \\\\ \n\\hline \\\\[-1.8ex] \nDf & 2 & 29.500 & 40.305 & 1 & 58 \\\\ \nSum Sq & 2 & 0.00000 & 0.00000 & 0.00000 & 0.00000 \\\\ \nMean Sq & 2 & 0.00000 & 0.00000 & 0.00000 & 0.00000 \\\\ \nF value & 1 & 10.164 &  & 10.164 & 10.164 \\\\ \nPr(\\textgreater F) & 1 & 0.002 &  & 0.002 & 0.002 \\\\ \n\\hline \\\\[-1.8ex] \n\\end{tabular} \n\\end{table} \n\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com\n% Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n\\begin{table}[!htbp] \\centering \n  \\caption{} \n  \\label{} \n\\begin{tabular}{@{\\extracolsep{5pt}}lccccc} \n\\\\[-1.8ex]\\hline \n\\hline \\\\[-1.8ex] \nStatistic & \\multicolumn{1}{c}{N} & \\multicolumn{1}{c}{Mean} & \\multicolumn{1}{c}{St. Dev.} & \\multicolumn{1}{c}{Min} & \\multicolumn{1}{c}{Max} \\\\ \n\\hline \\\\[-1.8ex] \nDf & 2 & 29.500 & 40.305 & 1 & 58 \\\\ \nSum Sq & 2 & 0.224 & 0.205 & 0.079 & 0.369 \\\\ \nMean Sq & 2 & 0.043 & 0.051 & 0.006 & 0.079 \\\\ \nF value & 1 & 12.395 &  & 12.395 & 12.395 \\\\ \nPr(\\textgreater F) & 1 & 0.001 &  & 0.001 & 0.001 \\\\ \n\\hline \\\\[-1.8ex] \n\\end{tabular} \n\\end{table} \n\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com\n% Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n\\begin{table}[!htbp] \\centering \n  \\caption{} \n  \\label{} \n\\begin{tabular}{@{\\extracolsep{5pt}}lccccc} \n\\\\[-1.8ex]\\hline \n\\hline \\\\[-1.8ex] \nStatistic & \\multicolumn{1}{c}{N} & \\multicolumn{1}{c}{Mean} & \\multicolumn{1}{c}{St. Dev.} & \\multicolumn{1}{c}{Min} & \\multicolumn{1}{c}{Max} \\\\ \n\\hline \\\\[-1.8ex] \nDf & 2 & 29.500 & 40.305 & 1 & 58 \\\\ \nSum Sq & 2 & 0.00000 & 0.00000 & 0.00000 & 0.00000 \\\\ \nMean Sq & 2 & 0.00000 & 0.00000 & 0.00000 & 0.00000 \\\\ \nF value & 1 & 10.164 &  & 10.164 & 10.164 \\\\ \nPr(\\textgreater F) & 1 & 0.002 &  & 0.002 & 0.002 \\\\ \n\\hline \\\\[-1.8ex] \n\\end{tabular} \n\\end{table} \n\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com\n% Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n\\begin{table}[!htbp] \\centering \n  \\caption{} \n  \\label{} \n\\begin{tabular}{@{\\extracolsep{5pt}}lccccc} \n\\\\[-1.8ex]\\hline \n\\hline \\\\[-1.8ex] \nStatistic & \\multicolumn{1}{c}{N} & \\multicolumn{1}{c}{Mean} & \\multicolumn{1}{c}{St. Dev.} & \\multicolumn{1}{c}{Min} & \\multicolumn{1}{c}{Max} \\\\ \n\\hline \\\\[-1.8ex] \nDf & 2 & 29.500 & 40.305 & 1 & 58 \\\\ \nSum Sq & 2 & 173,139.200 & 235,923.700 & 6,315.891 & 339,962.500 \\\\ \nMean Sq & 2 & 6,088.656 & 321.358 & 5,861.422 & 6,315.891 \\\\ \nF value & 1 & 1.078 &  & 1.078 & 1.078 \\\\ \nPr(\\textgreater F) & 1 & 0.304 &  & 0.304 & 0.304 \\\\ \n\\hline \\\\[-1.8ex] \n\\end{tabular} \n\\end{table} \n\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com\n% Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n\\begin{table}[!htbp] \\centering \n  \\caption{} \n  \\label{} \n\\begin{tabular}{@{\\extracolsep{5pt}}lccccc} \n\\\\[-1.8ex]\\hline \n\\hline \\\\[-1.8ex] \nStatistic & \\multicolumn{1}{c}{N} & \\multicolumn{1}{c}{Mean} & \\multicolumn{1}{c}{St. Dev.} & \\multicolumn{1}{c}{Min} & \\multicolumn{1}{c}{Max} \\\\ \n\\hline \\\\[-1.8ex] \nDf & 2 & 29.500 & 40.305 & 1 & 58 \\\\ \nSum Sq & 2 & 0.00000 & 0.00000 & 0.00000 & 0.00000 \\\\ \nMean Sq & 2 & 0.000 & 0.000 & 0.000 & 0.00000 \\\\ \nF value & 1 & 13.680 &  & 13.680 & 13.680 \\\\ \nPr(\\textgreater F) & 1 & 0.0005 &  & 0.0005 & 0.0005 \\\\ \n\\hline \\\\[-1.8ex] \n\\end{tabular} \n\\end{table} \n\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com\n% Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n\\begin{table}[!htbp] \\centering \n  \\caption{} \n  \\label{} \n\\begin{tabular}{@{\\extracolsep{5pt}}lccccc} \n\\\\[-1.8ex]\\hline \n\\hline \\\\[-1.8ex] \nStatistic & \\multicolumn{1}{c}{N} & \\multicolumn{1}{c}{Mean} & \\multicolumn{1}{c}{St. Dev.} & \\multicolumn{1}{c}{Min} & \\multicolumn{1}{c}{Max} \\\\ \n\\hline \\\\[-1.8ex] \nDf & 2 & 29.500 & 40.305 & 1 & 58 \\\\ \nSum Sq & 2 & 0.003 & 0.003 & 0.001 & 0.005 \\\\ \nMean Sq & 2 & 0.001 & 0.001 & 0.0001 & 0.001 \\\\ \nF value & 1 & 11.914 &  & 11.914 & 11.914 \\\\ \nPr(\\textgreater F) & 1 & 0.001 &  & 0.001 & 0.001 \\\\ \n\\hline \\\\[-1.8ex] \n\\end{tabular} \n\\end{table} \n\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com\n% Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n\\begin{table}[!htbp] \\centering \n  \\caption{} \n  \\label{} \n\\begin{tabular}{@{\\extracolsep{5pt}}lccccc} \n\\\\[-1.8ex]\\hline \n\\hline \\\\[-1.8ex] \nStatistic & \\multicolumn{1}{c}{N} & \\multicolumn{1}{c}{Mean} & \\multicolumn{1}{c}{St. Dev.} & \\multicolumn{1}{c}{Min} & \\multicolumn{1}{c}{Max} \\\\ \n\\hline \\\\[-1.8ex] \nDf & 2 & 29.500 & 40.305 & 1 & 58 \\\\ \nSum Sq & 2 & 0.002 & 0.002 & 0.001 & 0.004 \\\\ \nMean Sq & 2 & 0.0003 & 0.0003 & 0.0001 & 0.001 \\\\ \nF value & 1 & 7.848 &  & 7.848 & 7.848 \\\\ \nPr(\\textgreater F) & 1 & 0.007 &  & 0.007 & 0.007 \\\\ \n\\hline \\\\[-1.8ex] \n\\end{tabular} \n\\end{table} \n\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com\n% Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n\\begin{table}[!htbp] \\centering \n  \\caption{} \n  \\label{} \n\\begin{tabular}{@{\\extracolsep{5pt}}lccccc} \n\\\\[-1.8ex]\\hline \n\\hline \\\\[-1.8ex] \nStatistic & \\multicolumn{1}{c}{N} & \\multicolumn{1}{c}{Mean} & \\multicolumn{1}{c}{St. Dev.} & \\multicolumn{1}{c}{Min} & \\multicolumn{1}{c}{Max} \\\\ \n\\hline \\\\[-1.8ex] \nDf & 2 & 29.500 & 40.305 & 1 & 58 \\\\ \nSum Sq & 2 & 0.0001 & 0.0001 & 0.00000 & 0.0001 \\\\ \nMean Sq & 2 & 0.00000 & 0.00000 & 0.00000 & 0.00000 \\\\ \nF value & 1 & 0.046 &  & 0.046 & 0.046 \\\\ \nPr(\\textgreater F) & 1 & 0.830 &  & 0.830 & 0.830 \\\\ \n\\hline \\\\[-1.8ex] \n\\end{tabular} \n\\end{table} \n\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com\n% Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n\\begin{table}[!htbp] \\centering \n  \\caption{} \n  \\label{} \n\\begin{tabular}{@{\\extracolsep{5pt}}lccccc} \n\\\\[-1.8ex]\\hline \n\\hline \\\\[-1.8ex] \nStatistic & \\multicolumn{1}{c}{N} & \\multicolumn{1}{c}{Mean} & \\multicolumn{1}{c}{St. Dev.} & \\multicolumn{1}{c}{Min} & \\multicolumn{1}{c}{Max} \\\\ \n\\hline \\\\[-1.8ex] \nDf & 2 & 29.500 & 40.305 & 1 & 58 \\\\ \nSum Sq & 2 & 0.00000 & 0.00000 & 0.00000 & 0.00000 \\\\ \nMean Sq & 2 & 0.000 & 0.00000 & 0.000 & 0.00000 \\\\ \nF value & 1 & 10.011 &  & 10.011 & 10.011 \\\\ \nPr(\\textgreater F) & 1 & 0.002 &  & 0.002 & 0.002 \\\\ \n\\hline \\\\[-1.8ex] \n\\end{tabular} \n\\end{table} \n:::\n\n{{< pagebreak >}}\n\n# Conclusion\n\nFrom the performed data exploration we can conclude that particular data attributes have a patient specific distribution and correlation. This finding agrees with the general understanding that tumor mutations and reaction of immune system are patient and tumor specific and that a personalized approach is required. Additionally the data exploration shows that particular network attributes of the molecular structures are patient and tumor specific and that some of them show correlations with statistical significance with the produced PMBC values. That indicates that a machine learning approach that relies on these attributes as input can be applied to produce patient personalized predictions.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}