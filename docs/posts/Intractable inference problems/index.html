<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ivan Jacobs">
<meta name="dcterms.date" content="2023-03-02">

<title>Ivan Jacobs - Intractable inference problems</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../profile.jpg" rel="icon" type="image/jpeg">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Ivan Jacobs - Intractable inference problems">
<meta property="og:description" content="Sources: Matthew N. Bernstein blog, Deep Learning Book, Ian Good Fellow">
<meta property="og:site-name" content="Ivan Jacobs">
<meta name="twitter:title" content="Ivan Jacobs - Intractable inference problems">
<meta name="twitter:description" content="Sources: Matthew N. Bernstein blog, Deep Learning Book, Ian Good Fellow">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Ivan Jacobs</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/IvanJac20353450"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/ivanjacobs/"><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/ivanjacobs"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Intractable inference problems</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Evidence Lower Bound</div>
                <div class="quarto-category">Intractable Inference</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Ivan Jacobs </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 2, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>Sources: <a href="https://mbernste.github.io/posts/elbo/">Matthew N. Bernstein blog</a>, <a href="https://www.deeplearningbook.org/">Deep Learning Book, Ian Good Fellow</a></p>
<p>The term inference usually refers to computing the probability distribution of a set of variable when provided another set of variables. We usually are interested in computing <span class="math inline">\(p(z|v)\)</span>, in a context of latent variable or multitask learning when the task is defined by a vector <span class="math inline">\(z\)</span>. The challenge lays in the difficulty of computing <span class="math inline">\(p(z|v)\)</span> or the expected value with respect to it <span class="math inline">\(E_{z∼p(z|v)}\)</span></p>
<p>Intractable inference in deep learning arises from the connections between the activations generated from the multitude of layers that create either mutual ancestors or large cliques of activations. In order to solve the intractable inference problem we may approach it as an optimization problem and derive approximate inference algorithms that will approximate the underlying exact inference optimization.</p>
<p>To define an optimization problem we can assume that we have an observed data <span class="math inline">\(v\)</span> that is a realization of a random variable <span class="math inline">\(V\)</span>. We put forward the existence of another random variable <span class="math inline">\(Z\)</span> and <span class="math inline">\(V\)</span> and <span class="math inline">\(Z\)</span> are distributed according a joint distribution <span class="math inline">\(p(X,Z;\theta)\)</span> where <span class="math inline">\(\theta\)</span> parameterizes the distribution. The joint distribution indicates that <span class="math inline">\(Z\)</span> and <span class="math inline">\(V\)</span> are strongly correlated. Suppose <span class="math inline">\(m_z,m_v\)</span> are the means of <span class="math inline">\(z\)</span> and <span class="math inline">\(v\)</span> and are known, then we might be interested in the <span class="math inline">\(\sigma_{zv}\)</span> the covariance that measures the connection of <span class="math inline">\(z\)</span> and <span class="math inline">\(v\)</span>. <span id="eq-covariance"><span class="math display">\[\sigma_{zv}=E[(z-m_z)(v-m_v)] \tag{1}\]</span></span></p>
<p>Hence, to compute <span class="math inline">\(\sigma_{zv}\)</span> it is not enough to know the probability of <span class="math inline">\(z\)</span> and the probability of each <span class="math inline">\(v\)</span> but the joint probability of each pair <span class="math inline">\(z\)</span> and <span class="math inline">\(v\)</span>.</p>
<p>Suppose we run separate 2 experiments, the covariance between experiments for all pairs of <span class="math inline">\(z_i\)</span> and <span class="math inline">\(v_j\)</span> then equation (<a href="#eq-covariance">Equation&nbsp;1</a>)looks like: <span id="eq-covariance-12exp"><span class="math display">\[
\begin{aligned}
\sigma_{12}=E([(z-m_1)(v-m_2)])
\\
\sigma_{12}=\sum_{all}\sum_{ij}p_{ij}(z_i-m_1)(y_j-m_2)
\end{aligned}
\tag{2}\]</span></span> But <span class="math inline">\(v\)</span> is a realization from <span class="math inline">\(V\)</span> and not from <span class="math inline">\(Z\)</span> and therefor <span class="math inline">\(z\)</span> remains “latent” i.e.&nbsp;not observed. We might be interested in either computing the posteriour distribution <span class="math inline">\(p(Z|V;\theta)\)</span> given a fixed <span class="math inline">\(\theta\)</span> or finding the maximum likelihood <span class="math inline">\(argmaxv_{\theta}l(\theta)\)</span> where <span class="math inline">\(l(\theta)\)</span> is the log-likelihood function given an unknown <span class="math inline">\(\theta\)</span> defined by: <span id="eq-log-likelihood"><span class="math display">\[
l(\theta):=\log p(v;\theta)=\log\int_{z}p(v,z;\theta)dz
\tag{3}\]</span></span> We could envisage to compute the log-probability of the observed variable <span class="math inline">\(v\)</span> <span class="math inline">\(\log p(v;\theta)\)</span> but sometimes it is is to costly to marginalize out <span class="math inline">\(h\)</span> and this computation becomes difficult. Instead we can compute the evidence lower bound (ELBO) or variatonal free energy <span class="math inline">\(\mathcal{L}(v,\theta,q)\)</span> on <span class="math inline">\(\log(v;\theta)\)</span>. The evidence, in evidence lower bound, is the likelihood evaluated at a fixed <span class="math inline">\(\theta\)</span> : <span id="eq-evidence"><span class="math display">\[
evidence:\log p(v;\theta)
\tag{4}\]</span></span></p>
<p>Hence, if we have approximated <span class="math inline">\(\theta\)</span> well enough through our optimization approach we would expect that the marginal probability of the observed variable <span class="math inline">\(v\)</span> will be high. The evidence thus quantifies the quality of the approximation of <span class="math inline">\(p_{model}\)</span> parameterized by <span class="math inline">\(\theta\)</span> of <span class="math inline">\(p_{data}\)</span> i.e.&nbsp;<span class="math inline">\(p_{model}(z|v;\theta)\approx p_{data}(z|v)\)</span>.</p>
<p>If we consider that <span class="math inline">\(Z\)</span> follows an arbitrary probability distribution <span class="math inline">\(q\)</span> and that the joint distribution <span class="math inline">\(p(v,z;\theta):=p(v|z;\theta)q(z)\)</span>, then the evidence lower bound is the lower bound on the evidence that makes use of <span class="math inline">\(q\)</span>. Concretely : <span id="eq-elbo-log"><span class="math display">\[
\begin{aligned}
\log p(v;\theta)\ge \mathbb{E}_{z\sim q}\left[ \log \frac{p(v;z;\theta)}{q(z)} \right]
\end{aligned}
\tag{5}\]</span></span> where ELBO is the right-hand side of <a href="#eq-elbo-log">Equation&nbsp;5</a></p>
<p><span id="eq-elbo-elb"><span class="math display">\[
\begin{aligned}
ELBO:= \mathbb{E}_{z\sim q}\left[ \log \frac{p(v;z;\theta)}{q(z)} \right]
\end{aligned}
\tag{6}\]</span></span></p>
<p>The gap between the the evidence and the ELBO is the <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Kullback-Leibler divergence</a> between <span class="math inline">\(p(z|v;\theta)\)</span>. <span id="eq-KL-div"><span class="math display">\[
\begin{aligned}
D_{KL}(q(z)|| p(z|v;\theta))
\end{aligned}
\tag{7}\]</span></span> This lays the basis of the approximation approach called variational inference where we learn to infer <span class="math inline">\(q\)</span> through optimization algorithm. As long as <span class="math inline">\(z\)</span> is continuous, we can back-propagate through samples of <span class="math inline">\(z\)</span> dawn from <span class="math inline">\(q(z|v)=q(z;f(v;\theta))\)</span> to obtain a gradient with respect to <span class="math inline">\(\theta\)</span> in order to maximize <span class="math inline">\(\mathcal{L}(v,\theta,q)\)</span>. We can write <span class="math inline">\(\mathcal{L}(v,\theta,q)\)</span> as:</p>
<p><span id="eq-ELBO"><span class="math display">\[
\begin{aligned}
\mathcal{L}(v,\theta,q)=\log p(v;\theta) - D_{KL}(q(z|v)||p(z|v;\theta))
\end{aligned}
\tag{8}\]</span></span></p>
<p>where <span class="math inline">\(q\)</span> is an arbitrary probability distribution over <span class="math inline">\(z\)</span>. The difference between the expectation <span class="math inline">\(\log p(v)\)</span> and <span class="math inline">\(\mathcal{L}(v,\theta,q)\)</span> is given by the KL divergence that is always positive. We can conclude that <span class="math inline">\(\mathcal{L}\)</span> has at most the same value as the desired log-probability. If the two are equal <span class="math inline">\(q\)</span> has the same distribution as <span class="math inline">\(p(z|v)\)</span></p>
<p>We can rearrange <span class="math inline">\(\mathcal{L}\)</span> into:</p>
<p><span id="eq-ELBO-rearanged"><span class="math display">\[
\begin{aligned}
\mathcal{L}(v,\theta,q)=\log p(v;\theta) - D_{KL}(q(z|v)||p(z|v;\theta))
\\
=\log p(v;\theta) - \mathbb{E}_{z\sim q}\log \frac{q(z|v)}{p(z|v)}
\\
=\log p(v;\theta) - \mathbb{E}_{z\sim q}\log \frac{q(z|v)}{\frac{p(z,v;\theta)}{p(v;\theta)}}
\\
=\log p(v;\theta) - \mathbb{E}_{z\sim q} \left[\log q(z|v)-\log p(z,v;\theta) + \log p(v;\theta) \right]
\\
=-\mathbb{E}_{z\sim q} \left[\log q(z|v) - \log p(z,v;\theta) \right]
\end{aligned} \tag{9}\]</span></span></p>
<p>Hence a more canonical definition of the evidence lower bound can be defined as: <span id="eq-ELBO-canon"><span class="math display">\[
\begin{aligned}
\mathcal{L}(v,\theta,q)=\mathbb{E}_{z\sim q} \left[\log p(z,v)\right]+ H(q)
\end{aligned} \tag{10}\]</span></span></p>
<p>For an appropriate choice of <span class="math inline">\(q,\mathcal{L}\)</span> is tractable. For <span class="math inline">\(q(z|v)\)</span> that approximates <span class="math inline">\(p(z|v)\)</span> better, the lower bound <span class="math inline">\(\mathcal{L}\)</span> is closer to <span class="math inline">\(\log p(v)\)</span>. When <span class="math inline">\(q(z|v)=p(z|v)\)</span>, the approximation is perfect, hence, <span class="math inline">\(\mathcal{L}=\log p(v;\theta)\)</span>. Thus, we can think of variational inference as the procedure of finding <span class="math inline">\(q\)</span> that maximizes <span class="math inline">\(\mathcal{L}\)</span></p>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>