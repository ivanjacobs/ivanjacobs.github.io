[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am an AI & Cybersecurity Executive with 23+ years of global experience driving innovation across government, defense, critical infrastructure, and enterprise.\nMy career journey has spanned from building advanced data science platforms for the European Commission to spearheading agentic AI strategies at ST Engineering, where I lead the development of next-generation AI capabilities for national and enterprise security.\n\nI hold a Ph.D. in Business Administration (AI & Disruptive Innovation) and a Master’s in Data Science (RIT), with a focus on how humans and AI collaborate in decision-making, job transformation, and automation.\n\nRecognized for transforming foresight into execution, I:\n\nAuthored and executed a corporate Infosec AI Strategy that forecasted the rise of agentic AI years ahead of industry trends.\n\nBuilt and scaled high-performance AI teams, securing funding and national recognition.\n\nLed flagship AI partnerships with defense agencies and enterprises bridging public, private, and critical infrastructure domains.\n\nDelivered the first production-grade agentic AI SOC platform, now expanding into ASEAN and Middle Eastern markets.\n\n\nPublications:\n✨ Jacobs, Ivan, and Manolis Maragoudakis. 2021. “De Novo Drug Design Using Artificial Intelligence Applied on SARS-CoV-2 Viral Proteins ASYNT-GAN” BioChem 1, no. 1: 36-48. https://doi.org/10.3390/biochem1010004\n✨ IJacobs I, Ming LC, Mong J, Maragoudakis M and Malik N (2023) In silico antibody-peptide epitope prediction for personalized cancer therapy. Front. Appl. Math. Stat. 9:1150381. doi: 10.3389/fams.2023.1150381"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nArtificial Intelligence and the Shifting Balance of Power\n\n\n\n\n\n\nArtificial Intelligence\n\n\n\n\n\n\n\n\n\nSep 13, 2025\n\n\nIvan Jacobs\n\n\n\n\n\n\n\n\n\n\n\n\nIntractable inference problems\n\n\n\n\n\n\nEvidence Lower Bound\n\n\nIntractable Inference\n\n\n\n\n\n\n\n\n\nMar 2, 2023\n\n\nIvan Jacobs\n\n\n\n\n\n\n\n\n\n\n\n\nSolving Inverse Problems with score based generative modeling\n\n\n\n\n\n\nSolving Inverse Problems\n\n\n\n\n\n\n\n\n\nMar 2, 2023\n\n\nIvan Jacobs\n\n\n\n\n\n\n\n\n\n\n\n\nPublication:In silico Antibody-Peptide Epitope prediction for Personalized cancer therapy\n\n\n\n\n\n\nPersonalized therapy\n\n\nnetworks\n\n\nmachine learning\n\n\n\n\n\n\n\n\n\nMar 2, 2023\n\n\nIvan Jacobs\n\n\n\n\n\n\n\n\n\n\n\n\nAre tumors patient specific\n\n\n\n\n\n\nPersonalized therapy\n\n\nnetworks\n\n\nmachine learning\n\n\ndeep learning\n\n\n\n\n\n\n\n\n\nInvalid Date\n\n\nIvan Jacobs\n\n\n\n\n\n\n\n\n\n\n\n\nRA-DIT RETRIEVAL-AUGMENTED DUAL INSTRUCTION TUNING\n\n\n\n\n\n\nRA-DIT\n\n\nLLM\n\n\nRAG\n\n\n\n\n\n\n\n\n\nSep 13, 2025\n\n\nIvan Jacobs\n\n\n\n\n\n\n\n\n\n\n\n\nPolicy gradient methods\n\n\n\n\n\n\nReinforcement Learning\n\n\nReinforce\n\n\nPolicy gradient methods\n\n\nPolicy approximations\n\n\n\n\n\n\n\n\n\nMar 2, 2023\n\n\nIvan Jacobs\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Intractable inference problems/index.html",
    "href": "posts/Intractable inference problems/index.html",
    "title": "Intractable inference problems",
    "section": "",
    "text": "Sources: Matthew N. Bernstein blog, Deep Learning Book, Ian Good Fellow\nThe term inference usually refers to computing the probability distribution of a set of variable when provided another set of variables. We usually are interested in computing \\(p(z|v)\\), in a context of latent variable or multitask learning when the task is defined by a vector \\(z\\). The challenge lays in the difficulty of computing \\(p(z|v)\\) or the expected value with respect to it \\(E_{z∼p(z|v)}\\)\nIntractable inference in deep learning arises from the connections between the activations generated from the multitude of layers that create either mutual ancestors or large cliques of activations. In order to solve the intractable inference problem we may approach it as an optimization problem and derive approximate inference algorithms that will approximate the underlying exact inference optimization.\nTo define an optimization problem we can assume that we have an observed data \\(v\\) that is a realization of a random variable \\(V\\). We put forward the existence of another random variable \\(Z\\) and \\(V\\) and \\(Z\\) are distributed according a joint distribution \\(p(X,Z;\\theta)\\) where \\(\\theta\\) parameterizes the distribution. The joint distribution indicates that \\(Z\\) and \\(V\\) are strongly correlated. Suppose \\(m_z,m_v\\) are the means of \\(z\\) and \\(v\\) and are known, then we might be interested in the \\(\\sigma_{zv}\\) the covariance that measures the connection of \\(z\\) and \\(v\\). \\[\\sigma_{zv}=E[(z-m_z)(v-m_v)] \\tag{1}\\]\nHence, to compute \\(\\sigma_{zv}\\) it is not enough to know the probability of \\(z\\) and the probability of each \\(v\\) but the joint probability of each pair \\(z\\) and \\(v\\).\nSuppose we run separate 2 experiments, the covariance between experiments for all pairs of \\(z_i\\) and \\(v_j\\) then equation (Equation 1)looks like:\\[\n\\begin{aligned}\n\\sigma_{12}=E([(z-m_1)(v-m_2)])\n\\\\\n\\sigma_{12}=\\sum_{all}\\sum_{ij}p_{ij}(z_i-m_1)(y_j-m_2)\n\\end{aligned}\n\\tag{2}\\] But \\(v\\) is a realization from \\(V\\) and not from \\(Z\\) and therefor \\(z\\) remains “latent” i.e. not observed. We might be interested in either computing the posteriour distribution \\(p(Z|V;\\theta)\\) given a fixed \\(\\theta\\) or finding the maximum likelihood \\(argmaxv_{\\theta}l(\\theta)\\) where \\(l(\\theta)\\) is the log-likelihood function given an unknown \\(\\theta\\) defined by: \\[\nl(\\theta):=\\log p(v;\\theta)=\\log\\int_{z}p(v,z;\\theta)dz\n\\tag{3}\\] We could envisage to compute the log-probability of the observed variable \\(v\\) \\(\\log p(v;\\theta)\\) but sometimes it is is to costly to marginalize out \\(h\\) and this computation becomes difficult. Instead we can compute the evidence lower bound (ELBO) or variatonal free energy \\(\\mathcal{L}(v,\\theta,q)\\) on \\(\\log(v;\\theta)\\). The evidence, in evidence lower bound, is the likelihood evaluated at a fixed \\(\\theta\\) : \\[\nevidence:\\log p(v;\\theta)\n\\tag{4}\\]\nHence, if we have approximated \\(\\theta\\) well enough through our optimization approach we would expect that the marginal probability of the observed variable \\(v\\) will be high. The evidence thus quantifies the quality of the approximation of \\(p_{model}\\) parameterized by \\(\\theta\\) of \\(p_{data}\\) i.e. \\(p_{model}(z|v;\\theta)\\approx p_{data}(z|v)\\).\nIf we consider that \\(Z\\) follows an arbitrary probability distribution \\(q\\) and that the joint distribution \\(p(v,z;\\theta):=p(v|z;\\theta)q(z)\\), then the evidence lower bound is the lower bound on the evidence that makes use of \\(q\\). Concretely : \\[\n\\begin{aligned}\n\\log p(v;\\theta)\\ge \\mathbb{E}_{z\\sim q}\\left[ \\log \\frac{p(v;z;\\theta)}{q(z)} \\right]\n\\end{aligned}\n\\tag{5}\\] where ELBO is the right-hand side of Equation 5\n\\[\n\\begin{aligned}\nELBO:= \\mathbb{E}_{z\\sim q}\\left[ \\log \\frac{p(v;z;\\theta)}{q(z)} \\right]\n\\end{aligned}\n\\tag{6}\\]\nThe gap between the the evidence and the ELBO is the Kullback-Leibler divergence between \\(p(z|v;\\theta)\\). \\[\n\\begin{aligned}\nD_{KL}(q(z)|| p(z|v;\\theta))\n\\end{aligned}\n\\tag{7}\\] This lays the basis of the approximation approach called variational inference where we learn to infer \\(q\\) through optimization algorithm. As long as \\(z\\) is continuous, we can back-propagate through samples of \\(z\\) dawn from \\(q(z|v)=q(z;f(v;\\theta))\\) to obtain a gradient with respect to \\(\\theta\\) in order to maximize \\(\\mathcal{L}(v,\\theta,q)\\). We can write \\(\\mathcal{L}(v,\\theta,q)\\) as:\n\\[\n\\begin{aligned}\n\\mathcal{L}(v,\\theta,q)=\\log p(v;\\theta) - D_{KL}(q(z|v)||p(z|v;\\theta))\n\\end{aligned}\n\\tag{8}\\]\nwhere \\(q\\) is an arbitrary probability distribution over \\(z\\). The difference between the expectation \\(\\log p(v)\\) and \\(\\mathcal{L}(v,\\theta,q)\\) is given by the KL divergence that is always positive. We can conclude that \\(\\mathcal{L}\\) has at most the same value as the desired log-probability. If the two are equal \\(q\\) has the same distribution as \\(p(z|v)\\)\nWe can rearrange \\(\\mathcal{L}\\) into:\n\\[\n\\begin{aligned}\n\\mathcal{L}(v,\\theta,q)=\\log p(v;\\theta) - D_{KL}(q(z|v)||p(z|v;\\theta))\n\\\\\n=\\log p(v;\\theta) - \\mathbb{E}_{z\\sim q}\\log \\frac{q(z|v)}{p(z|v)}\n\\\\\n=\\log p(v;\\theta) - \\mathbb{E}_{z\\sim q}\\log \\frac{q(z|v)}{\\frac{p(z,v;\\theta)}{p(v;\\theta)}}\n\\\\\n=\\log p(v;\\theta) - \\mathbb{E}_{z\\sim q} \\left[\\log q(z|v)-\\log p(z,v;\\theta) + \\log p(v;\\theta) \\right]\n\\\\\n=-\\mathbb{E}_{z\\sim q} \\left[\\log q(z|v) - \\log p(z,v;\\theta) \\right]\n\\end{aligned} \\tag{9}\\]\nHence a more canonical definition of the evidence lower bound can be defined as: \\[\n\\begin{aligned}\n\\mathcal{L}(v,\\theta,q)=\\mathbb{E}_{z\\sim q} \\left[\\log p(z,v)\\right]+ H(q)\n\\end{aligned} \\tag{10}\\]\nFor an appropriate choice of \\(q,\\mathcal{L}\\) is tractable. For \\(q(z|v)\\) that approximates \\(p(z|v)\\) better, the lower bound \\(\\mathcal{L}\\) is closer to \\(\\log p(v)\\). When \\(q(z|v)=p(z|v)\\), the approximation is perfect, hence, \\(\\mathcal{L}=\\log p(v;\\theta)\\). Thus, we can think of variational inference as the procedure of finding \\(q\\) that maximizes \\(\\mathcal{L}\\)."
  },
  {
    "objectID": "posts/personalized therapy/index.html",
    "href": "posts/personalized therapy/index.html",
    "title": "Publication:In silico Antibody-Peptide Epitope prediction for Personalized cancer therapy",
    "section": "",
    "text": "In silico Antibody-Peptide Epitope prediction for Personalized cancer therapy\nThe human leukocyte antigen (HLA) system is a complex of genes on chromosome 6 in humans that encodes cell-surface proteins responsible for regulating the immune system. Viral peptides presented to cancer cell surfaces by the HLA trigger the immune system to kill the cells, creating Antibody-peptide epitopes (APE). This study proposes an in-silico approach to identify patient-specific APEs by applying complex networks diagnostics on a novel multiplex data structure as input for a deep learning model. The proposed analytical model identifies patient and tumor-specific APEs with as few as 20 labeled data points.\nAdditionally, the proposed data structure employs complex network theory and other statistical approaches that can better explain and reduce the black box effect of deep learning. The proposed approach achieves an F1-score of 80\\% and 93\\% on patients one and two respectively and above 90\\% on tumor-specific tasks. Additionally, it minimizes the required training time and the number of parameters.\nThe human leukocyte antigen (HLA) system or complex is a complex of genes on chromosome 6 in humans that encode cell-surface proteins responsible for regulating the immune system. The HLA system also known as the human version of the major histocompatibility complex (MHC) is found in many animals.\nHLA genes are highly polymorphic, which means that there are thousands of different forms of these genes called alleles, allowing them to fine-tune the adaptive immune system. The proteins encoded by certain genes are also known as antigens, because of their historic discovery as factors in organ transplants.\nAs shown in Figure \\ref{fig:1} HLA’s proteins present viral peptides from inside the cell to the surface of the cell. For example, if the cell is infected by a virus or is cancerous, the HLA system brings abnormal fragments, called peptides, to the surface of the cell so that the cell can be destroyed by the immune system.\n\n\n\nHLA proteins (green) display peptides (red) from inside the cell to help immune cells find cancerous or infected cells\n\n\nPredicting the specific HLA peptide combination that will present the peptide to the cell’s surface permits the creation of a treatment that will trigger the human immune system to destroy the cell.\nSpecifically, in cancer, this ability is essential, given that cancer is highly mutagenic with tumor and patient-specific mutations. This means that patients with the same tumor type will have different mutations that result in different reactions to the same treatment.\nAdvances in Deoxyribonucleic acid (DNA) sequencing, Messenger Ribonucleic acid (mRNA) vaccines, and high computational power allow us to work toward patient-specific therapy. This approach, called personalized mRNA-based antitumor vaccine, visualized in Figure \\ref{fig:2}, is bound to play a major role in the future.\n\n\n\nThe exome of tumor cells isolated from a biopsy sample and the exome of normal cells are compared to identify tumor-specific mutations. Point non-synonymous mutations, gene deletions, or rearrangements can give rise to neoantigens. Several bioinformatics tools are used to predict major histocompatibility complex (MHC) class I and class II binding (necessary for recognition by T cells) and RNA expression presence of the mutated antigen among tumor cells (clonality). RNA sequencing enables verification that the gene encoding the neoantigen is actually expressed by tumor cells. A tandem gene encoding several neoantigen peptides is cloned into a plasmid and transcribed to mRNA. Finally, these mRNAs are injected as naked RNA, formulated into liposomes, or loaded into dendritic cells.\n\n\nThe approach is meant to trigger an antitumor immune response in patients by challenging them with mRNAs encoding tumor-specific antigens \\citep{pastor_rna_2018}. These mRNAs can be directly injected as naked RNA or loaded into patient-derived dendritic cells.\nIn this work, we propose to extend the approach with additional laboratory and analytical optimization steps.\nConcretely DNA sequenced from the patient is used to select candidate peptides that will result from gene expression. As the space of possible combinations is huge a subset of potential peptides is synthesized and their reaction to the patient’s specific HLA alleles is tested by applying an enzyme-linked immunospot (ELISpot) assay.\nAn enzyme-linked immunospot (ELISpot) assay \\citep{engvall_enzyme-linked_1971}, shown in Figure \\ref{fig:3}, is a highly versatile and sensitive technique that is used for qualitative and quantitative measurement of the cytokine-secreting cells at the single-cell level. \\citep{paulie_chapter_2006}\n\n\n\nVisualisation of an enzyme-linked immunospot (ELISpot) Assa"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Hi, this is Ivan. I’m documenting my research journey here"
  },
  {
    "objectID": "posts/inverse problems/index.html",
    "href": "posts/inverse problems/index.html",
    "title": "Intractable inference problems with score based generative modeling",
    "section": "",
    "text": "An inverse problem seeks to recover unobserved causal factors from a set of observed measurements.If \\(x \\in \\mathbb{R}^n\\) is an unknown signal and \\(y \\in \\mathbb{R}^=Ax+\\epsilon\\) is a noisy observation with \\(m\\) linear measurements and \\(A\\in \\mathbb{R}^{m\\times n}\\) is a linear operator and \\(\\epsilon \\in \\mathbb{R^n}\\) is a noise vector. Solving the inverse problem constitutes of recovering \\(x\\) from its measurement \\(y\\). There is the assumption that \\(x\\) is sampled from a prior \\(p(x)\\) and as such the measurement and signal are connected trough a the measurement distribution \\(p(y|x)=q_{\\epsilon}(y-Ax)\\) with \\(q_{\\epsilon}\\) being the noise distribution of \\(\\epsilon\\). Given \\(p(y|x)\\) and \\(p(x)\\) the inverse problem can be solved by sampling from the posterior distribution \\(p(x|y)\\)."
  },
  {
    "objectID": "posts/inverse problems/index.html#background",
    "href": "posts/inverse problems/index.html#background",
    "title": "Solving Inverse Problems with score based generative modeling",
    "section": "Background",
    "text": "Background"
  },
  {
    "objectID": "posts/inverse problems/index.html#linear-inverse-problems",
    "href": "posts/inverse problems/index.html#linear-inverse-problems",
    "title": "Solving Inverse Problems with score based generative modeling",
    "section": "Linear inverse problems",
    "text": "Linear inverse problems\nAn inverse problem seeks to recover unobserved causal factors from a set of observed measurements.If \\(x \\in \\mathbb{R}^n\\) is an unknown signal and \\(y \\in \\mathbb{R}^m=Ax+\\epsilon\\) is a noisy observation with \\(m\\) linear measurements and \\(A\\in \\mathbb{R}^{m\\times n}\\) is a linear operator and \\(\\epsilon \\in \\mathbb{R^n}\\) is a noise vector. Solving the inverse problem constitutes of recovering \\(x\\) from its measurement \\(y\\). There is the assumption that \\(x\\) is sampled from a prior \\(p(x)\\) and as such the measurement and signal are connected trough a the measurement distribution \\(p(y|x)=q_{\\epsilon}(y-Ax)\\) with \\(q_{\\epsilon}\\) being the noise distribution of \\(\\epsilon\\). Given \\(p(y|x)\\) and \\(p(x)\\) the inverse problem can be solved by sampling from the posterior distribution \\(p(x|y)\\)."
  },
  {
    "objectID": "posts/inverse problems/index.html#score-based-generative-models",
    "href": "posts/inverse problems/index.html#score-based-generative-models",
    "title": "Solving Inverse Problems with score based generative modeling",
    "section": "Score-based generative models",
    "text": "Score-based generative models\nWhen solving an inverse problem we are given an observation \\(y\\), a measurement distribution \\(p(y|x)\\) and wish to sample from the posterior distribution \\(p(x|y)\\). The prior distribition \\(p(x)\\) is usually not known but we can use a generative model on a dataset $ {x_1,x_2 …x_n} p(x)$ to estimate the prior distribution. The posterior distribution \\(p(x|y)\\) can be determined through Bayes’ rule."
  },
  {
    "objectID": "posts/personalized therapy/In silico Antibody-Peptide Epitope prediction for Personalized cancer therapy/index.html",
    "href": "posts/personalized therapy/In silico Antibody-Peptide Epitope prediction for Personalized cancer therapy/index.html",
    "title": "Publication:In silico Antibody-Peptide Epitope prediction for Personalized cancer therapy",
    "section": "",
    "text": "In silico Antibody-Peptide Epitope prediction for Personalized cancer therapy\nThe human leukocyte antigen (HLA) system is a complex of genes on chromosome 6 in humans that encodes cell-surface proteins responsible for regulating the immune system. Viral peptides presented to cancer cell surfaces by the HLA trigger the immune system to kill the cells, creating Antibody-peptide epitopes (APE). This study proposes an in-silico approach to identify patient-specific APEs by applying complex networks diagnostics on a novel multiplex data structure as input for a deep learning model. The proposed analytical model identifies patient and tumor-specific APEs with as few as 20 labeled data points.\nAdditionally, the proposed data structure employs complex network theory and other statistical approaches that can better explain and reduce the black box effect of deep learning. The proposed approach achieves an F1-score of 80\\% and 93\\% on patients one and two respectively and above 90\\% on tumor-specific tasks. Additionally, it minimizes the required training time and the number of parameters.\nThe human leukocyte antigen (HLA) system or complex is a complex of genes on chromosome 6 in humans that encode cell-surface proteins responsible for regulating the immune system. The HLA system also known as the human version of the major histocompatibility complex (MHC) is found in many animals.\nHLA genes are highly polymorphic, which means that there are thousands of different forms of these genes called alleles, allowing them to fine-tune the adaptive immune system. The proteins encoded by certain genes are also known as antigens, because of their historic discovery as factors in organ transplants.\nAs shown in Figure \\ref{fig:1} HLA’s proteins present viral peptides from inside the cell to the surface of the cell. For example, if the cell is infected by a virus or is cancerous, the HLA system brings abnormal fragments, called peptides, to the surface of the cell so that the cell can be destroyed by the immune system.\n\n\n\nHLA proteins (green) display peptides (red) from inside the cell to help immune cells find cancerous or infected cells\n\n\nPredicting the specific HLA peptide combination that will present the peptide to the cell’s surface permits the creation of a treatment that will trigger the human immune system to destroy the cell.\nSpecifically, in cancer, this ability is essential, given that cancer is highly mutagenic with tumor and patient-specific mutations. This means that patients with the same tumor type will have different mutations that result in different reactions to the same treatment.\nAdvances in Deoxyribonucleic acid (DNA) sequencing, Messenger Ribonucleic acid (mRNA) vaccines, and high computational power allow us to work toward patient-specific therapy. This approach, called personalized mRNA-based antitumor vaccine, visualized in Figure \\ref{fig:2}, is bound to play a major role in the future.\n\n\n\nThe exome of tumor cells isolated from a biopsy sample and the exome of normal cells are compared to identify tumor-specific mutations. Point non-synonymous mutations, gene deletions, or rearrangements can give rise to neoantigens. Several bioinformatics tools are used to predict major histocompatibility complex (MHC) class I and class II binding (necessary for recognition by T cells) and RNA expression presence of the mutated antigen among tumor cells (clonality). RNA sequencing enables verification that the gene encoding the neoantigen is actually expressed by tumor cells. A tandem gene encoding several neoantigen peptides is cloned into a plasmid and transcribed to mRNA. Finally, these mRNAs are injected as naked RNA, formulated into liposomes, or loaded into dendritic cells.\n\n\nThe approach is meant to trigger an antitumor immune response in patients by challenging them with mRNAs encoding tumor-specific antigens \\citep{pastor_rna_2018}. These mRNAs can be directly injected as naked RNA or loaded into patient-derived dendritic cells.\nIn this work, we propose to extend the approach with additional laboratory and analytical optimization steps.\nConcretely DNA sequenced from the patient is used to select candidate peptides that will result from gene expression. As the space of possible combinations is huge a subset of potential peptides is synthesized and their reaction to the patient’s specific HLA alleles is tested by applying an enzyme-linked immunospot (ELISpot) assay.\nAn enzyme-linked immunospot (ELISpot) assay \\citep{engvall_enzyme-linked_1971}, shown in Figure \\ref{fig:3}, is a highly versatile and sensitive technique that is used for qualitative and quantitative measurement of the cytokine-secreting cells at the single-cell level. \\citep{paulie_chapter_2006}\n\n\n\nVisualisation of an enzyme-linked immunospot (ELISpot) Assa"
  },
  {
    "objectID": "posts/personalized therapy/Patient Specific tumor/index.html",
    "href": "posts/personalized therapy/Patient Specific tumor/index.html",
    "title": "Are tumors patient specific",
    "section": "",
    "text": "To address this question we compare the characteristics and derived network measures of antibody–peptide epitopes for patient 1 and patient 2 to show the patient-specific nature of tumors expressed through peptides originating from tumor-induced mutations. To do so, we apply statistical analysis techniques such as multivariate analysis of variance (MANOVA) on the network measures to evaluate if they are statistically significantly different per patient. In addition, we look at how different network measures correlate with PMBC values per patient. We apply a structure learning algorithm to the data to learn the structure of the directed acyclic graph (DAG) to analyze the causality of data features, i.e., network measures and the matched PBMC values. Finally, we compare the performance of personalized models on unseen data from different patients to understand if models can generalize over unseen data from different patients."
  },
  {
    "objectID": "posts/personalized therapy/Patient Specific tumor/index.html#data-overview",
    "href": "posts/personalized therapy/Patient Specific tumor/index.html#data-overview",
    "title": "Are tumors patient specific",
    "section": "Data Overview",
    "text": "Data Overview\n\nData Dictionary\nThe produced data’s attributes as listed in ?@tbl-data_dict_assays will give us the ability to create the network structures that represent the relationships between HLA alleles and peptides. This network structures will give us better insights and permit to apply analytical approaches to predict HLA-peptide interactions expressed as discretized class representing ranges of the numbers of matched blood mononuclear cells (PBMC’s).\n\n\n?(caption)\n\n\n\n\n\n\n\n\n\nData Sample\nA sample from the data as visualized in ?@tbl-data_sample_assays, shows 10 values of the peptide’s amino acids sequence with one letter code, the number of peptides per assay, the patients HLA’s and the measured ELISpot value i.e. blood mononuclear cells (PBMC’s).\n\n\n?(caption)\n\n\n\n\n\n\n\n\n\n\nELISpot value Distribution\nAs shown in ?@fig-elispot_values_hist, we wish to look at the distribution of the ELISpot values for both patients.The medians from both patients are different as well as the distribution of the values. The values of patient one are restricted to a smaller range and show an outlier in the upper quartile. In contrast patient two shows values distributed over a wider range, again with a wider distribution in the upper quartile.\nWe can conclude that the patients show different distributions of observed PBMC values, i.e. the PBMC values are patient specific.\nWarning: Use of `pationsOneandTwoDf$ELISPOTvalue` is discouraged.\nℹ Use `ELISPOTvalue` instead.\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\nSaving 7 x 5 in image\n\n\n\nPeptides nr. vs ELISpot Value\nIn ?@fig-elispot_values_violin, we graph a violin plot to analyze how the number of peptides in a system correlate with the PBMC values and specific patient. We see that patient two has systems with exclusively one peptide in contrast to patient one that has systems with one, two and three peptides. Patient one has sa high concentration of systems with only one peptide. The correlation between number of peptides and ELISPot values is not clear. Systems with one peptide seem to produce higher PBMC values in contrast to systems with multiple peptides. This conclusion should be take with caution since only patient one has systems with more than one peptide.\nSaving 7 x 5 in image\n\n\n\nNumber of Amino acids vs ELISpot values\nIn Figure 1, we analyze the distribution of ELISpot values in relation to the total number of Amino Acids originating from the peptides in a system. We look at these correlations for both patients individually and together. Here the difference between the patients is not so clear, we observe a pattern in both patients where the lower and the upper range of the number of patients correlate with a high ELISPot value. It is notisible that systems with 30 amino acids consistently produce PBMC values above 500 for patient two. We can conclude that systems with higher total number of amino acids in the peptides tend to produce higher ELISpot values.\n\n\n\n\nSaving 7 x 5 in image\nPicking joint bandwidth of 27.5\n\nSaving 7 x 5 in image\nPicking joint bandwidth of 169\n\nSaving 7 x 5 in image\nPicking joint bandwidth of 102\n\n\n \n\n\nFigure 1: Patient vs Tot. nr. Amino acids\n\n\n\n\n\nLinear Model coefficient analysis\nIn order to better understand the potential influence of particular data attributes we apply a linear regression model. Analyzing the coefficients we can understand the predictors influence on the produced PBMC values.\nFrom the results shown in Table 1, we can see that the total number of amino acids in a system have positive linear relationship with the produced PBMC’s for patient one and negative for patient two. The performance of the model differs between the two patients and the same coefficients have different linear relationship on the produced PBMC for the two patients. Hence the relationship between these coefficients and the matched PBMC value is patient specivif. This observation indicates that tumor mutations and immune system response are not only tumor but also patient specific.\n\nWarning: Model matrix is rank deficient. Parameters `Numberofpeptides` were not\n  estimable.\n\n\n\nTable 1: Linear Regression model comparison\n\n\n \nAll patients\nPatient 1.\nPatient 2.\n\n\nCoeffcient\nEstimates\nP-Value\nEstimates\nP-Value\nEstimates\nP-Value\n\n\nIntercept\n447.60\n0.017\n101.15\n0.011\n470.34\n0.067\n\n\nTot.Nr. Amino Acids\n4.64\n0.544\n3.22\n0.139\n-2.11\n0.853\n\n\nNr. of Peptides\n-210.97\n0.061\n-64.66\n0.006\n\n\n\n\nObservations\n65\n25\n40\n\n\nR2 / R2 adjusted\n0.055 / 0.025\n0.298 / 0.234\n0.001 / -0.025"
  },
  {
    "objectID": "posts/personalized therapy/Patient Specific tumor/index.html#multiplex-network",
    "href": "posts/personalized therapy/Patient Specific tumor/index.html#multiplex-network",
    "title": "Are tumors patient specific",
    "section": "Multiplex Network",
    "text": "Multiplex Network\nThe HLA-peptide interaction is dependent of the chemical reactions of atoms belonging to amino acids that will fall close enough in 3-dimensional space. To understand and study the diverse types of relations or interactions that exist between the components we chose a network representation with a notion of layers.\nThis type of networks is called multiplex networks as shown in Figure 5 where a node corresponds to a “physical object,” while node-layer pairs are different instances of the same object. For instance a node could represent an online user, while node-layer pairs would represent different accounts of the same user in different online social networks; or a node could\n\n\n\nFigure 5: Multiplex\n\n\nrepresent a social actor, while node-layer pairs would represent different social roles (friend, worker, family member) of the same social actor; or a node could stand for a location in a transportation network, while node-layer pairs would represent stations of different transportation modes (e.g., streets, highways, and subways).\nThe connection between nodes and node-layer pairs is given by the notion of supra-nodes: i.e., cliques in the supra-graph formed by node-layer pairs that are instances of the same object.\nTo correctly represent a physical object in the different layers of the multiplex we break down the peptides to amino acids and the amino acids to their smallest component atoms and their connections bonds. The layers coordinate, atom, monomer, polymer, complex and system are introduced.\n\nThe Atom layer, as shown in Figure 6, is the layer that represents the atoms and their bonds that construct objects in the monomer layer e.g., amino acid.\nThe Monomer layer, as shown in Figure 6, represents the objects of type monomer that is a molecule of any of a class of compounds, mostly organic, that can react with other molecules to form very large molecules, or polymers.\nThe Polymer layer, as shown in Figure 6, represents the objects of type polymer. Polymer is any object of a class of natural or synthetic substances composed of very large molecules, called macromolecules, which are multiples of monomers.\nThe Complex layer, as shown in Figure 6, represents polymers that form a complex by binding to each other e.g. peptide binds to a HLA to form a complex.\nThe System layer represents the totality of complexes that exist in an ELISpot assay and is representative of multiple HLA-peptide complexes. One system could be represented as shown in Figure 6 where we are omitting the coordinates layer.\n\n\n\nFigure 6: Multiplex Architecture"
  },
  {
    "objectID": "posts/personalized therapy/Patient Specific tumor/index.html#network-topological-attributes",
    "href": "posts/personalized therapy/Patient Specific tumor/index.html#network-topological-attributes",
    "title": "Are tumors patient specific",
    "section": "Network Topological Attributes",
    "text": "Network Topological Attributes\nTo compare and predict systems interactions and behavior we will look at measures and metrics that these networks express. Calculating and assigning these metrics for every individual system permits us to create a dataset that can be used in statistical, machine and deep learning analysis approaches. Additionally, we apply deep learning on graphs on the individual systems to make predictions of their interactions in this case the ELISpot result.\n\nSize largest Component\nIn undirected networks typically exists large components that fill most of the network, while the rest of the network is divided into a lot of small disconnected components. The size of the largest connected component can be expressed by: \\(S=1-e^{-cS}\\) introduced by Erdos and Renyi in 1958 where \\(c\\) denotes mean degree or the average of in- and out-going edges.\n\nWe compute the size of the largest component \\(S\\) of each system and and look at its distribution and correlation with the particular patient and the measured matched PBMC’s i.e. ELISpot values.\n\nAs visualized in Figure 7, even though the medians of both patients are close, the values of patient one are better distributed with a large portion in the lower quartile. Patient two shows a high concentration around the median and the upper quartile and an outlier in the upper whisker.\n\nWhen considering the \\(S\\) values over all the systems, we observe a positive correlation with the matched PBMC’s with statistical significance shown by a \\(p-value &lt;0.10\\).\nThis could mean that systems that create larger connected components, have a higher chance of producing a higher PBMC value. This is confirmed by the distribution of the PBMC values of patient two, showing overall significantly higher values than patient one, and a distribution of the size of the largest components that is concentrated around the median of 30 and the upper quartile.\nWhen looking at the individual patients, we observe that patient two shows inverse correlation, even though not significant, with the matched PBMC’s. Patient one shows a positive correlation with matched PBMC’s.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 7: Patient Matched PBMC’s vs. Size largest Component\n\n\n\n\n\n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nAvg. Spectral clustering\nA fast approach to separate a network in communities is by applying spectral modularity maximization by assigning a node to one of two groups communities. If we consider \\(s\\) as a vector in n-dimensional space, that implies that the vector must point to one of the corners of the n-dimensional hypercube. By creating a relaxed method where \\(s\\) is aloud to take any value of \\(|s|=\\sqrt{n}\\) the form we arrive at a matrix notation \\(Bs=\\beta s\\). Hense the optimal \\(s\\) is on of the eigenvectors of the modularity matrix and \\(\\beta\\) is the corresponding eigenvalue. We can find which eigenvector by applying \\[Q=\\dfrac{n}{4m}\\beta\\] Since \\(s^Ts=n\\) we can maximize the inner product \\(s^Tu=\\sum_is_iu_i\\). The maximum is achieved when \\(s_iu_i\\) is positive for all \\(i\\), which occurs when \\(s_i\\) has the same sign as \\(u_i\\) for all \\(i\\): \\[s_i=\\begin{cases}\n+1, & \\text{if } u_i&gt;0\\\\\n-1, & \\text{if }u_i&lt;0\n\\end{cases}\\]\nThis leads to a simple approach, we calculate the eigenvector of ton the modularity matrix corresponding to the highest eigenvalue and assign nodes ot communities according to the signs of the elements in this vector.\nWe slightly modify it by assigning zero to the nodes that correspond to negative eigenvalues instead of -1: \\[s_i=\\begin{cases}\n+1, & \\text{if } u_i&gt;0\\\\\n0, & \\text{if }u_i&lt;0\n\\end{cases}\\] Then we calculate the average \\(\\dfrac{1}{n}\\sum_{s=1}^{n}s_i\\) of the assigned values that produces a value between zero and one and is indicative of how balanced is the distribution of the nodes between two communities.\nIn Figure 8 we calculate the avg. spectral clustering for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC’s i.e. ELISpot values.\nWe see that the distributions for both patients are quite similar. Patient two produces values that are skewed towards the lower quartile while patient one values are better distributed around the median. Even though combined data of both patients show a inverse Pearson correlation coefficient with the matched PBMC’s, patient one shows a positive correlation with statistical significance indicated by a \\(p-value&lt;0.05\\).\nThis might indicate that there is a difference in the produced PMBC’s between patients with similar avg. spectral clustering values. In other words the systems of individual patients react differently to a similar internal node distribution between two communities.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 8: Patient Matched PBMC’s vs. Avg. Spectral clustering\n\n\n\n\n\n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nGlobal Clustering Coefficient\nClustering coefficient is a measure of the degree to which vertices in a network tend to create tightly knit groups, closed triads: \\[ C=\\dfrac{(\\text{number of closed paths of length two})}{(\\text{number of paths of length two})}\\] C=1 implies perfect transitivity,a networks whose components are all closed triads. C=0 implies no closed triads. Concretely we apply the Watts and Strogatz defined a clustering coefficient that quantifies the likelihood that two nodes that are connected to the same node are also connected to each other. degree to which vertices in a network tend to create tightly knit groups, closed triads: \\[ C=\\dfrac{(\\text{number of triangles})*3}{(\\text{number of connected triples})}\\] Concretely we apply the following formula \\[C=\\dfrac{1}{n}\\sum_{u=1}^{n}c_u\\] where \\(n\\) is the number of nodes and \\(c_u\\) is: \\[c_u = \\frac{2 T(u)}{deg(u)(deg(u)-1)}\\] where \\(T(u)\\) is the number of triangles through node \\(u\\) and \\(deg(u)\\) is the degree of \\(u\\).\nIn ?@fig-GlobalClusteringCoeffiecient we calculate global clustering coefficient for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC’s i.e. ELISpot values.\nWe see that the distributions for both patients are quite similar. Patient two produces values that are skewed towards the upper quartile while patient one values are better distributed around the median. Combined data of both patients shows a positive Pearson correlation coefficient,with statistical significance indicated by a \\(p-value&lt;0.05\\), with the matched PBMC’s. Patient one and two show a similar positive correlation.\nThis observation can imply that systems with high clustering coefficient, i.e. systems where monomers, polymers and atoms that are connected to the same monomer, polymer or atom have a high likelihood to be connected to each other, will produce a higher number of matched PBMC’s.\n\n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nTransitivity\nThe fundamental type of relation between nodes in a network is “connected by an edge.” If the “connected by an edge” relation were transitive it would mean that if node u is connected to node v, and v is connected to w, then u is also connected to w. \\[T = 3\\frac{\\#triangles}{\\#triads}\\] where “triads” are two edges with a shared vertex and triangles are loops of length three.\nIn ?@fig-Transitivity we calculate the transitivity for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC’s i.e. ELISpot values.\nWe see that the distributions for both patients are quite similar. Patient one produces values that are skewed towards the lower quartile while patient two values are better distributed around the median. Combined data of both patients show a positive Pearson correlation coefficient,with no statistical significance, with the matched PBMC’s. Patient one and two show a similar positive correlation.\nThis might confirm the observed correlation with the global clustering coefficient.\n\n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nAverage Degree\nThe average degree of a network:\\[\\langle k \\rangle=2\\frac{\\text{number of edges}}{\\text{number of nodes}}\\] is related to the density of the network, where in a dense network the average degree grows linearly with the number of nodes, while in a sparse network it grows sub linearly.\nIn Figure 9 we calculate \\(\\langle k \\rangle\\) for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC’s i.e. ELISpot values.\nWe see that the distributions for both patients are some what similar. Patient one produces values that are skewed towards the lower quartile while patient two values are better distributed around the median. The median of patient one is significantly higher.\nCombined data of both patients show an inverse Pearson correlation coefficient, with no statistical significance, with the matched PBMC’s. Patient two shows a similar positive correlation in contrast to patient one that shows a positive correlation.\nFrom these observations we could imply that impact of the density of the network on the matched PBMC’s is patient specific.\n\n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 9: Patient Matched PBMC’s vs. Average Degree\n\n\n\n\n\n\n\nDegree Centrality\nA large volume of work is dedicated to centrality. The question which are the most important vertices in or central nodes in a network. There are many possible definitions of importance and consequently many centrality measures. Degree, the number of incoming and outgoing edges a node has, is sometimes called degree centrality to emphasize its use as a centrality measure. Useful though it is quite a crude measure as it awards a node one centrality point for every neighbor it has. But not all neighbors are necessarily equivalent.\nIn Figure 10 we calculate the degree centrality for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC’s i.e. ELISpot values.\nWe see that the distributions for both patients are different. Patient one produces values that are mostly skewed towards the lower quartile while patient two are skewed towards the upper quartile. The median of patient one is significantly higher.\nCombined data of both patients show a positive Pearson correlation coefficient with a statistical significance indicated by a \\(p-value&lt;0.05\\), with the matched PBMC’s. Patient two shows a similar positive correlation in contrast to patient one that shows a correlation near to zero.\nFrom these observations we could imply that impact of high number of incoming and outgoing edges from the vertices in the system have a positive impact on the matched PBMC’s. There is however a patient specific aspect in the magnitude of the positive impact.\n\n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 10: Patient Matched PBMC’s vs. Degree Centrality\n\n\n\n\n\n\n\nAverage Core Hubs\nAverage core hubs is a measure of the average of the degrees of the top-100 hubs in a system:\\[\\dfrac{1}{n}\\sum_{i=1}^{100}k_i\\] where \\(k\\) is the degree of vertice i.\nIn Figure 11 we calculate the average core hubs for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC’s i.e. ELISpot values.\nWe see that the distributions for both patients are different. Patient one produces values that are mostly skewed towards the lower quartile while patient two skewed towards the upper quartile. The median of patient one is significantly higher.\nCombined data of both patients show a positive Pearson correlation coefficient with statistical significance indicated by a \\(p-value&lt;0.01\\), with the matched PBMC’s. Patient two shows a similar positive correlation in contrast to patient one that shows a correlation near to zero.\nFrom these observations we could imply that impact of high number of incoming and outgoing edges from the vertices in the system have a positive impact on the matched PBMC’s. There is however a patient specific aspect in the magnitude of the positive impact. This observation agrees with the observations of Degree Centrality and its correlation with the matched PBMC values.\n\n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 11: Patient Matched PBMC’s vs. Average Core Hubs\n\n\n\n\n\n\n\nDensity\nDensity of a graph is the ratio between the edges present in a graph and the maximum number of edges that the graph can contain. Conceptually, it provides an idea of how dense a graph is in terms of edge connectivity. \\[ d = \\frac{m}{n(n-1)}\\] where n is the number of nodes and m is the number of edges in a graph G.\nIn Figure 12 we calculate the density for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC’s i.e. ELISpot values.\nWe see that the distributions for both patients are different. Patient one produces values that are mostly skewed towards the lower quartile while patient’s two are skewed towards the upper quartile. The median of patient one is significantly higher.\nCombined data of both patients show a positive Pearson correlation coefficient with statistical significance indicated by a \\(p-value&lt;0.01\\), with the matched PBMC’s. Patient two shows a similar positive correlation in contrast to patient one that shows a correlation near to zero.\nFrom these observations we could imply that a high number of incoming and outgoing edges from the vertices in the system have a positive impact on the matched PBMC’s. There is however a patient specific aspect in the magnitude of the positive impact. This observation agrees with the observations of Degree Centrality and Average Core Hubs.As the measures, Density,Degree Centrality and Average Core Hubs, overlap it make sense to select the one with the highest correlation and statistical significance i.e. Average Core Hubs.\n\n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 12: Patient Matched PBMC’s vs. Density\n\n\n\n\n\n\n\n\nBetweenness Centrality\nBetweenness Centrality measures the importance of a node based on the number of paths between two other nodes that pass through it. Betweenness Centrality is a guide to the influence nodes have over the flow of information, energy between others. Betweenness Centrality \\(x_i\\) is given by \\[x_i=\\sum_{st}n^{i}_{st}\\] where \\(n^{i}_{st}\\) is the node \\(i\\) that lies on the shortest path from vertice \\(s\\) to \\(t\\).\nConcretely we average the betweennes centrality \\[ \\langle x\\rangle=\\dfrac{1}{n}\\sum_{i=1}^{n}x_i\\]\nIn Figure 13 we calculate the Betweenness Centrality for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC’s i.e. ELISpot values.\nWe see that the distributions for both patients are different. Patient one produces values that are mostly skewed towards the lower quartile while patient’s two are skewed towards the upper quartile. The median of patient one is significantly higher.\nCombined data of both patients show a positive Pearson correlation coefficient with statistical significance indicated by a \\(p-value&lt;0.01\\), with the matched PBMC’s. Patient two shows a similar positive correlation in contrast to patient one that shows a correlation near to zero.\nFrom these observations we could imply that impact of high number nodes in a system that are on the path between other nodes has a positive impact on the matched PBMC’s. There is however a patient specific aspect in the magnitude of the positive impact.\n\n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 13: Patient Matched PBMC’s vs. Average Betweenness Centrality\n\n\n\n\n\n\n\nCloseness Centrality\nCloseness centrality of a node u is the reciprocal of the average shortest path distance to u over all n-1 reachable nodes.\n\\[C(u) = \\frac{n - 1}{\\sum_{v=1}^{n-1} d(v, u)}\\],\nwhere d(v, u) is the shortest-path distance between v and u,and n is the number of nodes that can reach u. Concretely we average the betweennes centrality \\[ \\langle c\\rangle=\\dfrac{1}{n}\\sum_{u=1}^{n}c(u)\\]\nIn Figure 14 we calculate the Betweenness Centrality for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC’s i.e. ELISpot values.\nWe see that the distributions for both patients are different. Patient one produces values that are mostly skewed towards the lower quartile while patient two are evenly distributed. The median of patient one is significantly higher.\nCombined data of both patients show a positive Pearson correlation coefficient with statistical significance indicated by a \\(p-value&lt;0.05\\), with the matched PBMC’s. Patient one and two shows a similar positive correlation.\nFrom these observations we could imply that,the impact of high number nodes in a system with a high number of shortest distances to all other nodes, has a positive impact on the matched PBMC’s.\n\n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 14: Patient Matched PBMC’s vs. Closeness Centrality\n\n\n\n\n\n\n\nDegree Pearson Correlation Coefficient\nMeasures the degree assortativity of a network i.e. the similarity of connections in the graph with respect to the node degree.It varies between −1 ≤ r ≤ 1: For r &lt; 0 the network is assortative, for r = 0 the network is neutral and for r &gt; 0 the network is disassortative.\nIn Figure 15 we calculate the Degree Pearson correlation Coefficient for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC’s i.e. ELISpot values.\nWe see that the distributions for both patients are different. Patient one and two produce values that are mostly skewed towards the upper quartile but there is a significant difference in their medians.\nCombined data of both patients show a positive Pearson correlation coefficient with statistical significance indicated by a \\(p-value&lt;0.05\\), with the matched PBMC’s. Patient one and two show a similar positive correlation.\nFrom these observations we could imply that,a high number similar connections between nodes in a system e.g. monomers,polymers,atoms has a positive impact on the matched PBMC’s.\n\n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 15: Patient Matched PBMC’s vs. Degree Pearson Correlation Coefficient\n\n\n\n\n\n\n\nEigen Vector Centrality\nIn many circumstances a node’s importance in a network is increased by having connections with other nodes that are themselves important. Eigenvector centrality is an extension of degree centrality that takes this factor into account. Eigenvector centrality awards to a node a number of points proportional to the centrality scores of its neighbors. The eigenvector centrality \\(x_i\\) of node \\(i\\) is defined to be proportional to the sum of the centralities of i’s neighbors. The eigenvector centrality \\(x_i\\) of node i is defined to be proportional to the sum of the centralities of i’s neighbors\n\\[\nx_i=k^{-1} \\sum_{\\text{nodes j}\\\\ \\text{ neighbours of i}}x_j\n\\] In matrix notation \\[x=k^{-1} Ax\\\\ Ax=kx\\] where x is the vector with elements equal to the centrality scores x_i and k is a constant. In other words, x is an eigenvector of the adjacency matrix.\nIn Figure 16 we calculate the average Eigen Vector Centrality for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC’s i.e. ELISpot values.\nWe see that the distributions for both patients are very similar. Patient one and two produce values that are mostly skewed towards the upper quartile with patient two having a longer tail.\nCombined data of both patients show a positive Pearson correlation coefficient with no statistical significance , with the matched PBMC’s. However patient two shows an inverse correlation in contrast to positive correlation of patient one.\nFrom these observations we could imply that importance of this measure towards the impact on the matched PBMC’s is not significant and it is patient specific.\n\n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 16: Patient Matched PBMC’s vs. Eigen Vector Centrality\n\n\n\n\n\n\n\nPage Rank Centrality\nIf a node with high Katz centrality has edges pointing to many others, then all of those others also get high centrality. A high-centrality node pointing to one million others gives all one million of them high centrality. One could argue that this is not always appropriate. In many cases it means less if a node is only one among many that are pointed to. The centrality gained by virtue of receiving an edge from a prestigious node is diluted by being shared with so many others.\nWe can derive the following variant of Katz centrality in which the centrality we derive from the network neighbors is proportional to their centrality divided by their out-degree. \\[x_i=α\\sum_jA_{ij}\\frac{x_j}{k_j^{out}} +β\\]\nIn Figure 17\nwe calculate the average Page Rank Centrality for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC’s i.e. ELISpot values.\nWe see that the distributions for both patients are very different. Patient one and two produce similar medians but patient one distribution is skewed toward the lower quartile and patient two toward the higher quartile.\nCombined data of both patients show a positive Pearson correlation coefficient with statistical significance shown by a \\(p-value&lt;0.05\\), with the matched PBMC’s. Patient two has similar correlation.\nFrom these observations we could imply that systems with a high number of nodes that have a high centrality based on connections from nodes that on their turn have high centrality has a positive influence on the produced PMBC’s. However this influence seems to be patient specific.\n\n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 17: Patient Matched PBMC’s vs. Page Rank Centrality\n\n\n\n\n\n\n\nAttribute Assortativity Coefficient Source\nAssortativity measures the similarity of connections in the graph with respect to the attribute source. In the generated multiplex structure the attribute “source” refers to the unique id of the node the edge originates from.\nIn Figure 18 we calculate the average Attribute Assortativity Coefficient for attribute Source for each system and look at its distribution and correlation with the particular patient and the measured matched PBMC’s i.e. ELISpot values.\nWe see that the distributions for both patients are very different. Patient one and two produce similar medians but patient one distribution is skewed toward the upper quartile and patient two toward the lower quartile.\nCombined data of both patients show a inverse Pearson correlation coefficient with statistical significance shown by a \\(p-value&lt;0.05\\), with the matched PBMC’s. Patient one and two have similar correlation.\nFrom these observations we could imply that systems with a more diverse unique node distribution have a higher likelihood to produce more PMBC’s.\n\n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 18: Patient Matched PBMC’s vs. Attribute Assortativity Coefficient Source\n\n\n\n\n\n\n\nCausality Graph\nA Bayesian network is probabilistic model that represents the variables and their conditional dependencies as directed acyclic graph (DAG). In a DAG variables are represented as vertices and conditiononal dependencies as edges. Vertices that are not connected represent conditionally independent variables. Each node is associated with a probability function that takes in, a particular set of values for the node’s parent variables, and gives the probability, or probability distribution, of the variable represented by the node.\nAs shown in ?@fig-causality, we apply a structure learning algorithm to the data in order to learn the structure of the directed acyclic graph (DAG) from the data. Concretely we apply Incremental Association (IAMB) algorithm, based on the Markov blanket detection algorithm of the same name, which is based on a two-phase selection scheme (a forward selection followed by an attempt to remove false positives).\nAnalyzing the DAG we see that the matched PBMC, vectors,Average core hubs, Attribute Assortativity Coefficient Source,Size largest component, Eigen vector Centrality and closeness centrality are conditionally dependent on the patient. This observation confirms observations made the correlation analysis. This indicates that system structures have patient specific attributes and their matched PBMC’s are as well patient specific.\n\n\n\n\n\n\n\n\nMultivariate analysis of variance\nMultivariate analysis of variance (MANOVA) is a statistical procedure for comparison of multivariate sample means. It is often used when there are two or more dependent variables and we wish to perform regression analysis and analysis of variance for them by one or more factor variables or covariates.\nIn our case we wish to determine which network topology attributes are highly significantly different among patients.\nFrom the results shown in the following table, we see that Matched PBMC,Average Core hubs, Average Betweenness Centrality have a high statistical significance with \\(p-value&lt;0.001\\).\nCloseness Centrality,Degree Pearson Correlation Coefficient, Page Rank Centrality,Attribute Assortativity Coefficient Source with \\(p-value&lt;0.01\\)\nSize largest Component, Response Degree Centrality,Density statistical sigificance with \\(p-value&lt;0.05\\)\nFrom this analysis we can conclude that there are indications that the produced PBMC values are statistically significantly different per patient together with a number of topological network attributes. This is agrees with the observations in the distributions and the correlations with the produced PDBC’s.\n\n\n** Response Size largest Component**:\n\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nPatient\n1\n0.002939\n0.002939\n14.29\n0.000373\n\n\nResiduals\n58\n0.01193\n0.0002058\nNA\nNA\n\n\n\n** Response Laplacian clustering**:\n\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nPatient\n1\n7.603e-07\n7.603e-07\n1.128\n0.2927\n\n\nResiduals\n58\n3.91e-05\n6.742e-07\nNA\nNA\n\n\n\n** Response Global Clustering Coeffiecient**:\n\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nPatient\n1\n0.0002044\n0.0002044\n0.6412\n0.4265\n\n\nResiduals\n58\n0.01849\n0.0003187\nNA\nNA\n\n\n\n** Response Transitivity**:\n\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nPatient\n1\n0.01722\n0.01722\n7.502\n0.008175\n\n\nResiduals\n58\n0.1331\n0.002296\nNA\nNA\n\n\n\n** Response Average degree**:\n\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nPatient\n1\n5.252e-05\n5.252e-05\n0.05573\n0.8142\n\n\nResiduals\n58\n0.05466\n0.0009424\nNA\nNA\n\n\n\n** Response Average Clustering**:\n\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nPatient\n1\n6.182e-06\n6.182e-06\n3.257\n0.07631\n\n\nResiduals\n58\n0.0001101\n1.898e-06\nNA\nNA\n\n\n\n** Response Degree Centrality**:\n\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nPatient\n1\n8.194e-06\n8.194e-06\n0.1305\n0.7192\n\n\nResiduals\n58\n0.003641\n6.278e-05\nNA\nNA\n\n\n\n** Response Average Core hubs**:\n\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nPatient\n1\n0.0002156\n0.0002156\n0.6706\n0.4162\n\n\nResiduals\n58\n0.01865\n0.0003216\nNA\nNA\n\n\n\n** Response Density**:\n\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nPatient\n1\n6.182e-06\n6.182e-06\n3.257\n0.07631\n\n\nResiduals\n58\n0.0001101\n1.898e-06\nNA\nNA\n\n\n\n** Response Vectors**:\n\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nPatient\n1\n3.963e-07\n3.963e-07\n10.16\n0.002309\n\n\nResiduals\n58\n2.261e-06\n3.899e-08\nNA\nNA\n\n\n\n** Response Average Betweenness Centrality**:\n\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nPatient\n1\n0.07884\n0.07884\n12.39\n0.0008457\n\n\nResiduals\n58\n0.3689\n0.006361\nNA\nNA\n\n\n\n** Response Closeness Centrality**:\n\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nPatient\n1\n3.551e-07\n3.551e-07\n10.16\n0.002309\n\n\nResiduals\n58\n2.026e-06\n3.493e-08\nNA\nNA\n\n\n\n** Response Degree Pearson Correlation Coefficient**:\n\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nPatient\n1\n6316\n6316\n1.078\n0.3036\n\n\nResiduals\n58\n339962\n5861\nNA\nNA\n\n\n\n** Response Eigenvector Centrality**:\n\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nPatient\n1\n1.618e-08\n1.618e-08\n13.68\n0.0004833\n\n\nResiduals\n58\n6.86e-08\n1.183e-09\nNA\nNA\n\n\n\n** Response Page Rank Centrality**:\n\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nPatient\n1\n0.001067\n0.001067\n11.91\n0.001046\n\n\nResiduals\n58\n0.005193\n8.954e-05\nNA\nNA\n\n\n\n** Response Attribute Assortativity Coefficient Type**:\n\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nPatient\n1\n0.0005459\n0.0005459\n7.848\n0.006903\n\n\nResiduals\n58\n0.004034\n6.955e-05\nNA\nNA\n\n\n\n** Response Attribute Assortativity Coefficient Source**:\n\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nPatient\n1\n8.284e-08\n8.284e-08\n0.04645\n0.8301\n\n\nResiduals\n58\n0.0001034\n1.783e-06\nNA\nNA\n\n\n\n** Response Matched PBMC**:\n\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nPatient\n1\n2.488e-08\n2.488e-08\n10.01\n0.002478\n\n\nResiduals\n58\n1.442e-07\n2.486e-09\nNA\nNA\n\n\n\n\n\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com % Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com % Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com % Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com % Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com % Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com % Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com % Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com % Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com % Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com % Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com % Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com % Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com % Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com % Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com % Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com % Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com % Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\n% Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com % Date and time: Sat, Apr 01, 2023 - 7:52:51 AM\nMANOVA network topology attributes"
  },
  {
    "objectID": "posts/reinforce/index.html",
    "href": "posts/reinforce/index.html",
    "title": "Policy gradient methods",
    "section": "",
    "text": "Sources: (“Sutton & Barto Book: Reinforcement Learning: An Introduction,” n.d.; Weng 2018)\nIn this post, we explore approaches that involve the acquisition of a parameterized policy capable of selecting actions without reliance on a value function. While a value function may still play a role in learning the policy parameter, it is not obligatory for action selection. The notation \\(\\theta \\in \\mathbb{R}^{d'}\\)represents the parameter vector of the policy.\nConsequently, the expression \\(\\pi( a\\|s, \\theta) = Pr { A_t=a \\| S_t=s, \\theta\\_t=\\theta}\\) denotes the probability of taking action \\(a\\) at time \\(t\\), given that the environment is in state \\(s\\) at time \\(t\\), with parameter \\(\\theta\\). If a method incorporates a learned value function, the weight vector of the value function is denoted as \\(w \\in \\mathbb{R}^{d}\\), as in \\(\\hat{v}(s,w)\\).\nThis section delves into methodologies for learning the policy parameter based on the gradient of a scalar performance measure \\(J(\\theta)\\) concerning the policy parameter. These methodologies aim to maximize performance, and their updates approximate gradient ascent in J:\n\\[\\theta_{t+1} = \\theta_t + \\alpha \\widehat{\\nabla J(\\theta_t)}, \\]\nwhere \\(\\widehat{\\nabla J(\\theta_t)} \\in \\mathbb{R}^{d'}\\) is a stochastic estimate whose expectation approximates the gradient of the performance measure concerning the policy parameter \\(\\theta_t\\).\n\nPolicy approximation\nIn the context of policy gradient methods, the policy can adopt any parameterization, provided that \\(\\pi(a|s, \\theta)\\) is differentiable with respect to its parameters. Formally, this condition is satisfied as long as \\(\\nabla\\pi(a|s, \\theta)\\) (the column vector of partial derivatives of \\(\\pi(a|s, \\theta)\\) concerning the components of ) exists and is finite for all \\(s \\in S\\), \\(a \\in A(s)\\), and \\(\\theta \\in \\mathbb{R}^{d_0}\\). In practical terms, to ensure effective exploration, it is generally stipulated that the policy remains non-deterministic, i.e., \\(\\pi(a|s, \\theta) \\in (0, 1)\\) for all \\(s\\), \\(a\\), and \\(\\theta\\).\nWhen the action space is discrete and of manageable size, a prevalent approach is to employ a parameterization based on forming numerical preferences, denoted as \\(h(s, a, \\theta) \\in \\mathbb{R}\\) for each state–action pair. These preferences guide the selection of actions, with those having the highest preferences in each state being assigned the greatest probabilities of being chosen. An exemplar distribution employed for this purpose is the exponential soft-max distribution, expressed as:\n\\[ \\pi(a|s, \\theta) = \\frac{e^{h(s,a,\\theta)}}{\\sum_b e^{h(s,b,\\theta)}}\\]\nwhere \\(b\\) iterates over the possible actions in the state and \\(e \\approx 2.71828\\) is the base of the natural logarithm. This equation represents a particular form of the soft-max function commonly used in reinforcement learning and machine learning. It defines a probability distribution over a discrete set of actions in the context of a particular state \\(s\\) given a set of parameters \\(\\theta\\).\nHere’s a step-by-step explanation:\n\nDenominator:\n\n\\(e^{h(s, b, \\theta)}\\) represents the exponential of the action preference \\(h(s, b, \\theta)\\) for each possible action \\(b\\) in state \\(s\\). This is calculated for all actions in the denominator.\n\\(\\sum_b e^{h(s, b, \\theta)}\\) computes the sum of these exponentials over all possible actions in the state.\n\nNumerator:\n\n\\(e^{h(s, a, \\theta)}\\) represents the exponential of the numerical preference \\(h(s, a, \\theta)\\) for the specific action \\(a\\) in state \\(s\\). This is the preference associated with the action of interest in the numerator.\n\n\nWe call this kind of policy parameterization soft-max in action preferences. The soft-max in action preferences essentially takes the exponentiated preferences for each action and normalizes them to obtain probabilities. The probability of selecting action \\(a\\) in state \\(s\\) is given by the ratio of its preference to the sum of preferences for all actions. \\(\\pi(a|s, \\theta)\\) represents the probability of selecting action \\(a\\) in state \\(s\\) given the parameters \\(\\theta\\).\nIn simpler terms, the soft-max in action preferences converts a set of numerical preferences into a probability distribution. Actions with higher preferences have higher probabilities of being selected, but the distribution ensures that all probabilities sum to 1, making it a valid probability distribution. This is particularly useful in reinforcement learning, where it allows an agent to make probabilistic decisions based on learned preferences.\nThe preferences for actions can be parameterized in various ways. One approach is to compute them using a deep artificial neural network (ANN), where \\(\\theta\\) represents the vector of all connection weights in the network. Alternatively, preferences can be linear in features, expressed as:\n\\[ h(s, a, \\theta) = \\theta^Tx(s, a) \\]\nwhere \\(\\theta\\) represents the parameter vector, and \\(x(s, a) \\in \\mathbb{R}^{d'}\\) denotes the feature vector associated with state \\(s\\) and action \\(a\\).\nParameterizing policies using the soft-max in action preferences offers notable advantages over \\(\\epsilon-greedy\\) action selection and action-value methods. Firstly, the soft-max allows the approximate policy to approach a deterministic policy, whereas \\(\\epsilon-greedy\\) methods always maintain a non-zero probability of selecting a random action. Even if a soft-max distribution is applied to action values, it alone cannot guide the policy towards determinism; instead, the action-value estimates converge to true values, leading to specific probabilities other than 0 and 1. Adjusting the temperature parameter in the soft-max distribution could approach determinism over time, but determining an appropriate reduction schedule is challenging without substantial prior knowledge.\nIn contrast, action preferences, parameterized through the soft-max, do not converge to specific values; rather, they are designed to generate the optimal stochastic policy. If the optimal policy is deterministic, the preferences for optimal actions are driven infinitely higher than for suboptimal actions, assuming the chosen parameterization allows for such distinctions.\nA second advantage is that soft-max parameterization enables the selection of actions with arbitrary probabilities. In problems involving substantial function approximation, the best approximate policy may be stochastic. For instance, in card games with imperfect information, optimal play often involves blending two actions with specific probabilities, such as bluffing in Poker. Action-value methods lack a natural mechanism for discovering stochastic optimal policies, while policy-approximating methods, particularly those utilizing the soft-max, can accommodate and discover such stochastic optimal policies.\n\n\nThe Policy Gradient Theorem\nIn addition to the practical benefits of policy parameterization over \\(\\epsilon-greedy\\) action selection, there exists a significant theoretical advantage. Continuous policy parameterization ensures that the action probabilities change smoothly with respect to the learned parameters. In contrast, \\(\\epsilon-greedy\\) selection may lead to abrupt changes in action probabilities for even a minor alteration in estimated action values, especially when a different action attains the maximum value. This inherent smoothness in the dependence of policy on parameters contributes to stronger convergence guarantees for policy-gradient methods compared to action-value methods. Specifically, the continuity of the policy’s dependence on parameters facilitates the approximation of gradient ascent in policy-gradient methods.\nFor the episodic case we can define the performance measure as the value of the start state of the episode. By assuming that every episode starts in some particular (non-random) state \\(s_0\\) we simplify the notation. Then,in the episodic case we define performance as \\[\nJ(\\theta)\\doteq v_\\pi(s_0)\n\\] where \\(v_{\\pi{_\\theta}}\\) is the true value function for \\(\\pi_\\theta\\) and the policy is determined by \\(\\theta\\).\nChallenges in Changing Policy Parameters with Function Approximation:\n\nDependency on Both Action Selections and State Distribution: Problem: Performance is influenced by both the choices of actions and the distribution of states where these actions occur. Implication: Altering the policy parameter impacts both action selections and state distributions.\nComputational Challenge in State Distribution Effects: Problem: While the effect of the policy parameter on actions and rewards can be computed straightforwardly, the impact on the state distribution is typically unknown. Implication: Estimating the performance gradient is complicated when the effect of policy changes on the state distribution is uncertain.\nUnknown Environment Influence: Problem: The effect of the policy on the state distribution is a function of the environment and is often not known. Implication: The challenge lies in estimating the gradient when changes in policy influence the state distribution, the details of which are not explicitly known.\n\nIn summary, the difficulty arises in effectively changing policy parameters for improvement when the performance gradient is contingent on the unknown consequences of policy adjustments on the state distribution.\nFortunately, the policy gradient theorem offers a concise and theoretical solution to this challenge. It provides an analytical expression for the gradient of performance concerning the policy parameter, crucial for approximating gradient ascent. \\[\n\\nabla v^\\pi(s) = \\nabla \\left[ \\sum_{a} \\pi(a|s)q_\\pi(s, a) \\right]\n,\\text{ for all s} \\in S\\\\\n\\] \\[\n\\begin{align*}\n&= \\sum_a \\Biggl[ \\nabla\\pi(a|s)q_\\pi(s, a) + \\pi(a|s)\\nabla q_\\pi(s, a) \\Biggr] \\quad \\tag{1. product rule of calculus}\\label{eq:a} \\\\\n&= \\sum_a \\Biggl[ \\nabla\\pi(a|s)q_\\pi(s, a) + \\pi(a|s)\\nabla \\sum_{s',r'} p(s', r'|s, a)(r+v_\\pi(s'))  \\Biggr]  \\quad \\tag{2}\\label{eq:a2} \\\\\n&= \\sum_a \\Biggl[ \\nabla\\pi(a|s)q_{\\pi}(s, a) + \\pi(a|s) \\sum_{s'} p(s' |s, a)\\nabla v_{\\pi}(s') \\Biggr]  \\quad \\tag{3}\\label{eq:a3}\\\\\n&= \\sum_a \\Biggl[ \\nabla\\pi(a|s)q_{\\pi}(s, a) + \\pi(a|s) \\sum_{s'} p(s' |s, a) \\quad     \n\\qquad  \\sum_{a'} \\Bigl[ \\nabla\\pi(a'|s')q_{\\pi}(s', a') + \\pi(a'|s') \\sum_{s''} p(s'' |s', a')\\nabla v_\\pi(s'') \\Bigr] \\Biggr] \\nonumber \\tag{4. Unrolling}\\label{eq:a4} \\\\\n&= \\sum_{x \\in S}  \\sum_{k=0}^{\\infty} Pr(s \\to x, k, \\pi) \\sum_a \\nabla\\pi(a|x)q_{\\pi}(x, a) \\tag{5}\\label{eq:a5}\n\\end{align*}\n\\] Let’s walk through the proof:\n\\(\\eqref{eq:a}\\) and \\(\\eqref{eq:a2}\\):\nLet’s break down each step in detail:\nInitial Expression: \\[ = \\sum_a \\Biggl[ \\nabla\\pi(a|s)q_\\pi(s, a) + \\pi(a|s)\\nabla q_\\pi(s, a) \\Biggr] \\quad \\text{(product rule of calculus)}\\]\nIn this step, the product rule of calculus is applied. The product rule states that the derivative of a product of two functions is the derivative of the first function times the second function, plus the first function times the derivative of the second function. Here, the functions are \\(\\pi(a|s)\\) and \\(q_\\pi(s, a)\\).\nFurther Expansion: \\[\n= \\sum_a \\Biggl[ \\nabla\\pi(a|s)q_\\pi(s, a) + \\pi(a|s)\\nabla \\sum_{s',r'} p(s', r'|s, a)\\Bigl[r+v_\\pi(s')\\Bigr]  \\Biggr] \\quad \\text{(further expansion)}\\]\nThe second term \\(\\pi(a|s)\\nabla q_\\pi(s, a)\\) is further expanded using the definition of \\(q_\\pi(s, a)\\) as the expected sum of future rewards. This involves taking the derivative with respect to \\(a\\) and considering the probability distribution \\(p(s', r'|s, a)\\). The sum is taken over all possible future states \\(s'\\) and rewards \\(r'\\).\nBecause \\(P(s' \\vert s, a) = \\sum_r P(s', r \\vert s, a)\\) we can express \\(\\eqref{eq:a2}\\) as \\(\\eqref{eq:a3}\\):\n\\[\\sum_a \\Biggl[ \\nabla\\pi(a|s)q_{\\pi}(s, a) + \\pi(a|s) \\sum_{s'} p(s' |s, a)\\nabla v_{\\pi}(s') \\Biggr]\\]\nThis equation has a nice recursive form (see the red parts!) and the future state value function \\(V^\\pi(s’)\\) can be repeated unrolled by following the same equation.\nLet’s look at how to arrive at \\(\\eqref{eq:a5}\\) from \\(\\eqref{eq:a4}\\):\n\nLet’s consider the following visitation sequence and label the probability of transitioning from state \\(s\\) to state \\(x\\) with policy \\(\\pi_\\theta\\) after \\(k\\) step as \\(\\rho^\\pi(s \\to x, k)\\). \\[s \\xrightarrow[]{a \\sim \\pi_\\theta(.\\vert s)} s' \\xrightarrow[]{a \\sim \\pi_\\theta(.\\vert s')} s'' \\xrightarrow[]{a \\sim \\pi_\\theta(.\\vert s'')} \\dots\\]\n\nWhen \\(k = 0\\): \\(\\rho^\\pi(s \\to s, k=0) = 1\\).\nWhen \\(k = 1\\), we scan through all possible actions and sum up the transition probabilities to the target state: \\(\\rho^\\pi(s \\to s’, k=1) = \\sum_a \\pi_\\theta(a \\vert s) P(s’ \\vert s, a)\\).\nImagine that the goal is to go from state \\(s\\) to \\(x\\) after \\(k+1\\) steps while following policy \\(\\pi_\\theta\\) . We can first travel from \\(s\\) to a middle point \\(s’\\) (any state can be a middle point,) after \\(k\\) steps and then go to the final state \\(x\\) during the last step. In this way, we are able to update the visitation probability recursively: \\(\\rho^\\pi(s \\to x, k+1) = \\sum_{s’} \\rho^\\pi(s \\to s’, k) \\rho^\\pi(s’ \\to x, 1)\\).\nThen we go back to unroll the recursive representation of \\(\\nabla_\\theta V^\\pi(s)\\)!\nLet \\(\\phi(s) = \\sum{a \\in \\mathcal{A}} \\nabla\\theta \\pi_\\theta(a \\vert s)Q^\\pi(s, a)\\) to simplify the maths. If we keep on extending \\(\\nabla_\\theta V^\\pi(.)\\) infinitely, it is easy to find out that we can transition from the starting state \\(s\\) to any state after any number of steps in this unrolling process and by summing up all the visitation probabilities, we get \\(\\nabla_\\theta V^\\pi(s)\\)!\n\n\\[\n\\begin{align*}& \\color{red}{\\nabla_\\theta V^\\pi(s)}= \\\\&= \\phi(s) + \\sum_a \\pi_\\theta(a \\vert s) \\sum_{s'} P(s' \\vert s,a) \\color{red}{\\nabla_\\theta V^\\pi(s')} \\\\&= \\phi(s) + \\sum_{s'} \\sum_a \\pi_\\theta(a \\vert s) P(s' \\vert s,a) \\color{red}{\\nabla_\\theta V^\\pi(s')} \\\\&= \\phi(s) + \\sum_{s'} \\rho^\\pi(s \\to s', 1) \\color{red}{\\nabla_\\theta V^\\pi(s')} \\\\&= \\phi(s) + \\sum_{s'} \\rho^\\pi(s \\to s', 1) \\color{red}{\\nabla_\\theta V^\\pi(s')} \\\\&= \\phi(s) + \\sum_{s'} \\rho^\\pi(s \\to s', 1) \\color{red}{[ \\phi(s') + \\sum_{s''} \\rho^\\pi(s' \\to s'', 1) \\nabla_\\theta V^\\pi(s'')]} \\\\&= \\phi(s) + \\sum_{s'} \\rho^\\pi(s \\to s', 1) \\phi(s') + \\sum_{s''} \\rho^\\pi(s \\to s'', 2)\\color{red}{\\nabla_\\theta V^\\pi(s'')} \\scriptstyle{\\text{ ; Consider }s'\\text{ as the middle point for }s \\to s''}\\\\&= \\phi(s) + \\sum_{s'} \\rho^\\pi(s \\to s', 1) \\phi(s') + \\sum_{s''} \\rho^\\pi(s \\to s'', 2)\\phi(s'') + \\sum_{s'''} \\rho^\\pi(s \\to s''', 3)\\color{red}{\\nabla_\\theta V^\\pi(s''')} \\\\&= \\dots \\scriptstyle{\\text{; Repeatedly unrolling the part of }\\nabla_\\theta V^\\pi(.)} \\\\&= \\sum_{x\\in\\mathcal{S}}\\sum_{k=0}^\\infty \\rho^\\pi(s \\to x, k) \\phi(x)\\end{align*}\n\\] The nice rewriting above allows us to exclude the derivative of Q-value function, \\(\\nabla_\\theta Q^\\pi(s, a)\\). By plugging it into the objective function \\(J(\\theta)\\), we are getting the following: \\[\\begin{aligned}\n\\nabla_\\theta J(\\theta)\n&= \\nabla_\\theta V^\\pi(s_0) & \\scriptstyle{\\text{; Starting from a random state } s_0} \\\\\n&= \\sum_{s}\\color{blue}{\\sum_{k=0}^\\infty \\rho^\\pi(s_0 \\to s, k)} \\phi(s) &\\scriptstyle{\\text{; Let }\\color{blue}{\\eta(s) = \\sum_{k=0}^\\infty \\rho^\\pi(s_0 \\to s, k)}} \\\\\n&= \\sum_{s}\\eta(s) \\phi(s) & \\\\\n&= \\Big( {\\sum_s \\eta(s)} \\Big)\\sum_{s}\\frac{\\eta(s)}{\\sum_s \\eta(s)} \\phi(s) & \\scriptstyle{\\text{; Normalize } \\eta(s), s\\in\\mathcal{S} \\text{ to be a probability distribution.}}\\\\\n&\\propto \\sum_s \\frac{\\eta(s)}{\\sum_s \\eta(s)} \\phi(s) & \\scriptstyle{\\sum_s \\eta(s)\\text{  is a constant}} \\\\\n&= \\sum_s d^\\pi(s) \\sum_a \\nabla_\\theta \\pi_\\theta(a \\vert s)Q^\\pi(s, a) & \\scriptstyle{d^\\pi(s) = \\frac{\\eta(s)}{\\sum_s \\eta(s)}\\text{ is stationary distribution.}}\n\\end{aligned}\\] In the episodic case, the constant of proportionality \\(\\sum_s \\eta(s)\\) is the average length of an episode; in the continuing case, it is 1 (“Sutton & Barto Book: Reinforcement Learning: An Introduction,” n.d.)Sec. 13.2. The gradient can be further written as:\n\\[\n\\begin{aligned}\\nabla_\\theta J(\\theta) &\\propto \\sum_{s \\in \\mathcal{S}} d^\\pi(s) \\sum_{a \\in \\mathcal{A}} Q^\\pi(s, a) \\nabla_\\theta \\pi_\\theta(a \\vert s)  &\\\\&= \\sum_{s \\in \\mathcal{S}} d^\\pi(s) \\sum_{a \\in \\mathcal{A}} \\pi_\\theta(a \\vert s) Q^\\pi(s, a) \\frac{\\nabla_\\theta \\pi_\\theta(a \\vert s)}{\\pi_\\theta(a \\vert s)} &\\\\&= \\mathbb{E}_\\pi [Q^\\pi(s, a) \\nabla_\\theta \\ln \\pi_\\theta(a \\vert s)] & \\scriptstyle{\\text{; Because } (\\ln x)' = 1/x}\\end{aligned}\n\\]\nWhere \\(\\mathbb{E}\\_\\pi\\) refers to \\(\\mathbb{E}_{s \\sim d_\\pi, a \\sim \\pi_\\theta}\\) when both state and action distributions follow the policy \\(\\pi_\\theta\\)(on policy).\nThe policy gradient theorem lays the theoretical foundation for various policy gradient algorithms. This vanilla policy gradient update has no bias but high variance. Many following algorithms were proposed to reduce the variance while keeping the bias unchanged.\n\\[\\nabla_\\theta J(\\theta)  = \\mathbb{E}_\\pi [Q^\\pi(s, a) \\nabla_\\theta \\ln \\pi_\\theta(a \\vert s)]\\]\n\n\n\n\n\nReferences\n\n“Sutton & Barto Book: Reinforcement Learning: An Introduction.” n.d. http://incompleteideas.net/book/the-book-2nd.html.\n\n\nWeng, Lilian. 2018. “Policy Gradient Algorithms.” https://lilianweng.github.io/posts/2018-04-08-policy-gradient/."
  },
  {
    "objectID": "posts/RA-DIT RETRIEVAL AUGMENTED DUAL INSTRUCTION/index.html",
    "href": "posts/RA-DIT RETRIEVAL AUGMENTED DUAL INSTRUCTION/index.html",
    "title": "RA-DIT RETRIEVAL-AUGMENTED DUAL INSTRUCTION TUNING",
    "section": "",
    "text": "Retrieval-Augmented Dual Instruction Tuning (RA-DIT)\nIn this post, I explain the approach called Retrieval-Augmented Dual Instruction Tuning (RA-DIT) (Lin et al., n.d.) that leverages both language model (LM) fine-tuning and retriever fine-tuning to significantly boost the performance of RALMs, especially in scenarios that require access to large, external knowledge sources. The approach is based on the idea of fine-tuning a pre-trained LLM and a state-of-the-art dense retriever together, using a combination of supervised and unsupervised objectives.\nThe authors use a retrieval-augmenting pre-trained auto-regressive language model, specifically LLAMA, in combination with a dual-encoder based retriever architecture. The retriever is initialized using DRAGON+, a state-of-the-art dual-encoder model. Let’s break down the key components and equations mentioned in the passage.\n\nLanguage Model (LLAMA):\n\nThe language model used is LLAMA, a family of open-sourced language models pre-trained on trillions of tokens (Brown et al., 2020).\nIt is a retrieval-augmenting pre-trained auto-regressive language model.\n\nRetriever Architecture:\n\nThe retriever adopts a dual-encoder based architecture, known for its ease of fine-tuning and efficiency at the inference stage (Lewis et al., 2020; Izacard et al., 2022b; Shi et al., 2023b).\n\nDocument and Query Encoders:\n\nGiven a corpus \\(C\\) and a query \\(q\\), the document encoder maps each text chunk \\(c\\) in \\(C\\) to an embedding \\(Ed(c)\\).\nThe query encoder maps the query \\(q\\) to an embedding \\(Eq(q)\\).\n\nRetrieval Process:\n\nThe top-k relevant text chunks for the query \\(q\\) are retrieved based on the query-document embedding similarity.\nThe similarity score \\(s(q, c)\\) between the query \\(q\\) and a document chunk \\(c\\) is computed using the dot product of their respective embeddings: \\[s(q, c) = Eq(q) \\cdot Ed(c)\\] Let’s break this down and explain how the similarity \\(s(q, c)\\) is computed using a dot product, and provide a brief proof for the equation \\(s(q, c) = Eq(q) \\cdot Ed(c)\\).\nThe dot product of two vectors \\(A = [a_1, a_2, ..., a_n]\\) and \\(B = [b_1, b_2, ..., b_n]\\) is given by: \\(A \\cdot B = a_1 \\cdot b_1 + a_2 \\cdot b_2 + \\ldots + a_n \\cdot b_n\\)\nThe dot product is used to compute the similarity between the query embedding \\(Eq(q)\\) and the document embedding \\(Ed(c)\\). The embeddings are vectors in a high-dimensional space. It is a measure of the cosine of the angle between two vectors, and in the context of embeddings, it helps capture the semantic similarity between the query and document. Higher dot product values imply greater similarity, and the retriever uses this similarity score to retrieve relevant text chunks.\nThe similarity \\(s(q, c)\\) is computed as the dot product between the query embedding vector \\(Eq(q)\\) and the document embedding vector \\(Ed(c)\\). This can be represented as: \\(s(q, c) = Eq(q) \\cdot Ed(c)\\)\nLet \\(Eq(q) = [eq_1, eq_2, ..., eq_k]\\) be the components of the query embedding vector, and \\(Ed(c) = [ed_1, ed_2, ..., ed_k]\\) be the components of the document embedding vector. The dot product is then given by: \\(s(q, c) = eq_1 \\cdot ed_1 + eq_2 \\cdot ed_2 + \\ldots + eq_k \\cdot ed_k\\)\nThis computation effectively measures the similarity between the query and document embeddings by multiplying their corresponding components and summing the results. If the vectors are similar, the dot product will be larger, indicating higher similarity. Conversely, if the vectors are dissimilar, the dot product will be smaller.\n\nRetriever Initialization:\n\nThe retriever is initialized using DRAGON+, a state-of-the-art dual-encoder model.\nDRAGON+ is trained with a contrastive learning objective and large-scale data augmentation (Lin et al., 2023).\n\nIn summary, the retriever uses dual encoders to map documents and queries into embeddings, and it retrieves relevant text chunks based on the similarity between the query and document embeddings. The initialization of the retriever is done using a high-performing model, DRAGON+, trained with a contrastive learning objective.\nParallel In-Context Retrieval-Augmentation:\n\nParallel In-Context Retrieval-Augmentation technique, building on the work of Shi et al. (2023b). This technique involves retrieving top-k relevant text chunks for a given language model prompt and augmenting the prompt with each retrieved chunk. The language model predictions are then computed in parallel, and the final output probability is a mixture of the probabilities from each augmented prompt, weighted by the chunk relevance score.\nLet’s break down the key components and equations mentioned in the passage:\nRetrieval Process:\n\nFor a given language model prompt \\(x\\), top-k relevant text chunks \\(C'\\) are retrieved from the corpus \\(C\\). Each retrieved chunk is denoted as \\(c\\), and \\(|C'| = k\\).\n\nAugmentation:\n\nTo stay within the context window size limit, each retrieved chunk \\(c\\) is prepended individually to the prompt \\(x\\).\n\nParallel Computation:\n\nLanguage model predictions from multiple augmented prompts are computed in parallel.\n\nOutput Probability Calculation:\nThe final output probability \\(p_{LM}(y|x, C')\\) is a mixture of the probability from each augmented prompt, weighted by the chunk relevance score.\n\\(p_{LM}(y|x, C') = \\sum_{c \\in C'} p_{LM}(y|c \\circ x) \\cdot p_{R}(c|x)\\) (Equation 2)\nwhere:\n\n\\(\\circ\\) denotes sequence concatenation.\n\\(p_{LM}(y|c \\circ x)\\) is the probability of language model predictions for the augmented prompt.\n\\(p_{R}(c|x) = \\frac{e^{s(x,c)}}{\\sum_{c' \\in C'} e^{s(x,c')}}\\) is the chunk relevance score, which represents the retriever scores normalized among the top-k relevant chunks.\n\nExplanation: The equation sums up the probabilities of language model predictions for each augmented prompt, where each prompt is formed by concatenating a retrieved chunk \\(c\\) with the original prompt \\(x\\). - The probability \\(p_{R}(c|x)\\) is the chunk relevance score, representing how relevant the retrieved chunk \\(c\\) is to the original prompt \\(x\\). It is calculated by exponentiating the retriever scores and normalizing them among the top-k relevant chunks. - The final output probability is a weighted sum of these probabilities, where each term is weighted by the relevance of the corresponding retrieved chunk.\nIn summary, the Parallel In-Context Retrieval-Augmentation technique involves retrieving relevant chunks, augmenting the prompt with each chunk, computing language model predictions in parallel, and combining the probabilities in a weighted manner based on chunk relevance scores.\n\n\nRETRIEVAL AUGMENTED LANGUAGE MODEL FINE-TUNING\nThe approach involves incorporating in-context retrieval augmentation during the fine-tuning process. Let’s break down the key components and equations mentioned in the passage:\n\nFine-Tuning Setup:\n\nThe language model is fine-tuned on selected datasets \\(DL\\) with in-context retrieval augmentation.\nEach fine-tuning sequence is separated into an instruction segment \\(x\\) and an output segment \\(y\\).\n\nRetrieval of Relevant Text Chunks:\n\nFor each example \\((x_i, y_i) \\in DL\\), the top-˜k relevant text chunks \\(C_i\\) are retrieved based on \\(x_i\\).\nFor each retrieved chunk \\(c_{ij} \\in C_i\\), a separate fine-tuning example is created by prepending it to the instructions as a background field.\nThis results in ˜k independent fine-tuning instances per original example: \\({(c_{ij} \\circ x_i, y_i) | j = 1, ..., ˜k}\\).\n\nFine-Tuning Objective:\n\nThe language model is fine-tuned using the next-token prediction objective.\nThe loss function \\(L(DL)\\) is defined as the negative log likelihood of the language model predicting the output segment \\(y_i\\) given the augmented input \\(c_{ij} \\circ x_i\\). \\[L(DL) = - \\sum_i \\sum_j \\log p_{LM}(y_i|c_{ij} \\circ x_i)\\] (Equation 3)\n\nBenefits of In-Context Retrieval Augmentation:\n\nIn-context retrieval augmentation during fine-tuning provides a twofold benefit.\n\nFirst, it helps the language model better utilize relevant background knowledge to make predictions.\nSecond, it allows the language model to handle cases where even state-of-the-art retrievers may falter and return inaccurate results. Training the language model to make correct predictions in such cases enables it to ignore misleading retrieval content and rely on its parametric knowledge.\n\n\n\nHere is a vanilla implementation of the fine-tuning process with in-context retrieval augmentation in PyTorch:\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments\n# Load the pre-trained language model and tokenizer\nmodel = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased')\ntokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n# Define the dataset and data loader\nclass FineTuningDataset(Dataset):\n    def __init__(self, texts, labels):\n        self.texts = texts\n        self.labels = labels\n    def __len__(self):\n        return len(self.texts)\n    def __getitem__(self, index):\n        text = self.texts[index]\n        label = self.labels[index]\n        return {\n            'text': tokenizer.encode(text, return_tensors='pt'),\n            'label': torch.tensor(label, dtype=torch.long)\n        }\ndef get_relevant_text_chunks(texts, k):\n    # Use a retrieval model to retrieve the top-k relevant text chunks\n    # and return a set of vectors representing the relevant text chunks\n    pass\n# Fine-tune the language model\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=3,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=64,\n    evaluation_strategy='epoch',\n    learning_rate=5e-5,\n    save_total_limit=2,\n    save_steps=500,\n    load_best_model_at_end=True,\n    metric_for_best_model='accuracy',\n    greater_is_better=True,\n    save_strategy='steps',\n    save_on_each_node=True,\n)\ndata_loader = DataLoader(FineTuningDataset(train_texts, train_labels), batch_size=training_args.per_device_train_batch_size, shuffle=True)\nfor epoch in range(training_args.num_train_epochs):\n    model.train()\n    for batch in data_loader:\n        text = batch['text'].to(device)\n        label = batch['label'].to(device)\n        optimizer.zero_grad()\n        outputs = model(text)\n        loss = nn.CrossEntropyLoss()(outputs, label)\n        loss.backward()\n        optimizer.step()\n    # Compute the loss for the fine-tuning instances\n    total_loss = 0\n    for batch in data_loader:\n        text = batch['text'].to(device)\n        label = batch['label'].to(device)\n        outputs = model(text)\n        loss = nn.CrossEntropyLoss()(outputs, label)\n        total_loss += loss.item()\n    print(f'Epoch {epoch+1}, Loss: {total_loss / len(data_loader)}')\nIn this implementation, we first load the pre-trained language model and tokenizer. We then define a custom dataset class FineTuningDataset to store the training data, and create a data loader from the dataset. We define a function get_relevant_text_chunks to retrieve the top-\\(k\\) relevant text chunks for each example, and use the retrieved chunks to create separate fine-tuning instances. We then fine-tune the language model using the next-token prediction objective, and compute the loss for the fine-tuning instances. Note that the implementation above is a simplified version of the original approach, and may not be directly applicable to all scenarios. The original approach may involve additional preprocessing steps, such as tokenization and padding, and may use different retrieval models and evaluation metrics.\nExplanation:\nThe fine-tuning process involves extending each training example by incorporating relevant background information retrieved from the corpus. - The fine-tuning objective is to minimize the negative log likelihood of the language model’s predictions for the output segment, given the augmented input. - The strategy helps the language model adapt to utilize relevant background knowledge during prediction and handle cases where retrieved information might be incorrect or misleading.\nIn summary, the fine-tuning strategy with in-context retrieval augmentation enhances the language model’s ability to utilize retrieved information by adapting to relevant background knowledge and handling inaccuracies in retrieval content. The empirical efficacy of this approach is demonstrated in §5.1 of the document.\nRETRIEVER FINE-TUNING The process of fine-tuning the retriever to align its output with the language model by leveraging a generalized version of LSR (LM-Supervised Retrieval) training. The goal is to use the language model itself to provide supervision for retriever fine-tuning. Let’s break down the key components and equations mentioned in the passage:\n\nGeneralized LSR Training:\n\nLSR (LM-Supervised Retrieval) training is a method that utilizes the language model to provide supervision for retriever fine-tuning.\nA generalized version of LSR training is adopted.\n\nLSR Score Calculation:\n\nFor a training sample \\((x, y)\\) in the retriever fine-tuning dataset \\(DR\\), the LSR score for a retrieved chunk \\(c\\) is defined as: \\(p_{LSR}(c|x, y) = \\frac{\\sum_{c' \\in C} \\exp\\left(\\frac{pLM(y|c' \\circ x)}{\\tau}\\right)}{\\sum_{c' \\in C'} \\exp\\left(\\frac{pLM(y|c' \\circ x)}{\\tau}\\right)}\\) (Equation 4) where:\n\n\\(\\tau\\) is a temperature hyperparameter.\n\\(C' \\subset C\\) denotes the top-k retrieved chunks for \\(x\\).\n\nA higher LSR score indicates that \\(c\\) is more effective at improving the language model’s chance of predicting the correct answer.\n\nTraining Objective:\n\nThe training objective is to minimize the Kullback-Leibler (KL) divergence between the retriever scores \\(p_{R}(c|x)\\) (defined in Eq. 2) and the LSR scores \\(p_{LSR}(c|x, y)\\): \\[L(D_R) = \\mathbb{E}_{(x, y) \\in D_R} \\text{KL}\\left[p_{R}(c|x) \\, \\|\\, p_{LSR}(c|x, y)\\right]\\] (Equation 5)\n\nUpdate Strategy:\n\nIn practice, only the query encoder of the retriever is updated during fine-tuning, as updating both encoders is found to hurt performance (as mentioned in §5.1).\n\n\nExplanation:\nLSR score computation involves normalizing the exponential of language model prediction scores for retrieved chunks by the temperature parameter \\(\\tau\\).\nThe goal of LSR training is for the retriever to assign higher scores to chunks that can improve the language model’s likelihood of generating the correct answer. - The training objective, expressed as the KL divergence, measures the difference between the retriever scores and the LSR scores. Minimizing this divergence encourages the retriever to align its outputs with the language model’s predictions. - The update is performed only on the query encoder of the retriever during fine-tuning, as updating both encoders negatively impacts performance.\nIn summary, the passage describes a fine-tuning strategy for the retriever that incorporates LSR training, leveraging the language model for supervision. This approach aims to improve the alignment between the retriever’s output and the language model’s predictions.\n\n\n\n\n\nReferences\n\nLin, Xi Victoria, Xilun Chen, Mingda Chen, Weijia Shi, Maria Lomeli, Rich James, Pedro Rodriguez, et al. n.d. “RA-DIT: Retrieval-Augmented Dual Instruction Tuning.” https://doi.org/10.48550/arXiv.2310.01352."
  },
  {
    "objectID": "posts/Artificial Intelligence and the Shifting Balance of Power/index.html",
    "href": "posts/Artificial Intelligence and the Shifting Balance of Power/index.html",
    "title": "Artificial Intelligence and the Shifting Balance of Power",
    "section": "",
    "text": "Artificial Intelligence (AI) is no longer confined to research labs or experimental pilot programs. Today, it is a decisive factor in business strategy, shaping how companies compete, grow, and innovate. The latest Critical & Emerging Technologies Index underscores AI’s transformative impact—not just on technology, but on global market dynamics, geopolitical influence, and corporate leadership.\nIn this article, we explore how AI is driving competitive advantage, the global trends that matter for business, and actionable strategies for companies that want to lead rather than follow.\n\n\nTraditionally, businesses approached AI as a way to reduce costs or automate routine processes. While operational efficiency remains important, AI’s role has expanded to become a strategic differentiator. Companies integrating AI across product development, customer engagement, and decision-making are building capabilities that are difficult to replicate, giving them a durable competitive edge.\nKey strategic benefits include:\n\nEnhanced decision-making: AI-driven analytics and predictive models allow firms to anticipate market shifts, optimize operations, and improve forecasting accuracy.\nCustomer-centric innovation: From personalized recommendations to dynamic pricing, AI enables more responsive, tailored experiences.\nResilience and scalability: Intelligent automation and risk modeling help companies respond quickly to disruptions while scaling operations efficiently.\n\nHowever, these advantages are contingent on three critical resources: talent, data, and compute infrastructure. Companies that can secure and integrate these resources will lead the AI-powered economy, while others risk falling behind.\n\n\n\nThe Critical & Emerging Technologies Index highlights significant regional trends, each with unique implications for businesses:\n\n\nU.S. firms dominate in frontier models, advanced algorithms, and high-performance compute infrastructure. The combination of world-class research institutions, venture capital, and entrepreneurial culture enables rapid commercialization of cutting-edge AI products. For businesses, this ecosystem accelerates access to the latest tools and talent.\n\n\n\nChinese companies excel in lean AI architectures and low-cost training pipelines, allowing them to scale AI solutions quickly and affordably. Global businesses must recognize this rising competition and consider strategies for efficiency, pricing, and market positioning to maintain their edge.\n\n\n\nEurope emphasizes trustworthy AI, prioritizing compliance, ethics, and regulatory alignment. While innovation may be slower, European firms benefit from credibility in regulated markets, increasingly valued by clients worldwide who prioritize safety, accountability, and data privacy.\n\n\n\nCountries like India, Brazil, and the UAE possess rich talent pools and data availability but lag in compute infrastructure. As cloud adoption expands and infrastructure improves, these markets could leapfrog in AI capabilities, creating opportunities for partnerships, joint ventures, and rapid scaling.\n\n\n\n\nFor companies aiming to leverage AI as a strategic advantage, the following considerations are critical:\n\nInvest in compute access: Partnerships with cloud providers and national or sovereign compute strategies will be pivotal for scaling AI-driven products.\nPrioritize talent pipelines: Attracting, training, and retaining top-tier AI researchers and engineers will be a defining competitive differentiator.\nBalance compliance and innovation: Navigating divergent regulatory landscapes—especially between the EU, U.S., and China—is essential for global operations.\nMonitor the cost curve: Efficiency innovations, particularly from Chinese competitors, will influence pricing strategies and product design decisions.\n\n\n\n\nLooking ahead, AI will not merely support business operations—it will redefine them. From supply chains to customer experience to product design, every layer of business is being touched by AI. Companies that view AI as a strategic capability rather than a technological tool are the ones poised to shape entire industries.\nThe Critical & Emerging Technologies Index makes it clear: AI is no longer a technology choice—it’s a leadership decision. Companies that recognize this shift, invest accordingly, and execute thoughtfully will define the market leaders of the next decade.\nCritical and Emerging Technologies Index"
  },
  {
    "objectID": "posts/Artificial Intelligence and the Shifting Balance of Power/index.html#ai-from-efficiency-tool-to-strategic-asset",
    "href": "posts/Artificial Intelligence and the Shifting Balance of Power/index.html#ai-from-efficiency-tool-to-strategic-asset",
    "title": "Artificial Intelligence and the Shifting Balance of Power",
    "section": "",
    "text": "Traditionally, businesses approached AI as a way to reduce costs or automate routine processes. While operational efficiency remains important, AI’s role has expanded to become a strategic differentiator. Companies integrating AI across product development, customer engagement, and decision-making are building capabilities that are difficult to replicate, giving them a durable competitive edge.\nKey strategic benefits include:\n\nEnhanced decision-making: AI-driven analytics and predictive models allow firms to anticipate market shifts, optimize operations, and improve forecasting accuracy.\nCustomer-centric innovation: From personalized recommendations to dynamic pricing, AI enables more responsive, tailored experiences.\nResilience and scalability: Intelligent automation and risk modeling help companies respond quickly to disruptions while scaling operations efficiently.\n\nHowever, these advantages are contingent on three critical resources: talent, data, and compute infrastructure. Companies that can secure and integrate these resources will lead the AI-powered economy, while others risk falling behind."
  },
  {
    "objectID": "posts/Artificial Intelligence and the Shifting Balance of Power/index.html#global-ai-trends-with-business-implications",
    "href": "posts/Artificial Intelligence and the Shifting Balance of Power/index.html#global-ai-trends-with-business-implications",
    "title": "Artificial Intelligence and the Shifting Balance of Power",
    "section": "",
    "text": "The Critical & Emerging Technologies Index highlights significant regional trends, each with unique implications for businesses:\n\n\nU.S. firms dominate in frontier models, advanced algorithms, and high-performance compute infrastructure. The combination of world-class research institutions, venture capital, and entrepreneurial culture enables rapid commercialization of cutting-edge AI products. For businesses, this ecosystem accelerates access to the latest tools and talent.\n\n\n\nChinese companies excel in lean AI architectures and low-cost training pipelines, allowing them to scale AI solutions quickly and affordably. Global businesses must recognize this rising competition and consider strategies for efficiency, pricing, and market positioning to maintain their edge.\n\n\n\nEurope emphasizes trustworthy AI, prioritizing compliance, ethics, and regulatory alignment. While innovation may be slower, European firms benefit from credibility in regulated markets, increasingly valued by clients worldwide who prioritize safety, accountability, and data privacy.\n\n\n\nCountries like India, Brazil, and the UAE possess rich talent pools and data availability but lag in compute infrastructure. As cloud adoption expands and infrastructure improves, these markets could leapfrog in AI capabilities, creating opportunities for partnerships, joint ventures, and rapid scaling."
  },
  {
    "objectID": "posts/Artificial Intelligence and the Shifting Balance of Power/index.html#key-business-takeaways",
    "href": "posts/Artificial Intelligence and the Shifting Balance of Power/index.html#key-business-takeaways",
    "title": "Artificial Intelligence and the Shifting Balance of Power",
    "section": "",
    "text": "For companies aiming to leverage AI as a strategic advantage, the following considerations are critical:\n\nInvest in compute access: Partnerships with cloud providers and national or sovereign compute strategies will be pivotal for scaling AI-driven products.\nPrioritize talent pipelines: Attracting, training, and retaining top-tier AI researchers and engineers will be a defining competitive differentiator.\nBalance compliance and innovation: Navigating divergent regulatory landscapes—especially between the EU, U.S., and China—is essential for global operations.\nMonitor the cost curve: Efficiency innovations, particularly from Chinese competitors, will influence pricing strategies and product design decisions."
  },
  {
    "objectID": "posts/Artificial Intelligence and the Shifting Balance of Power/index.html#ai-as-a-leadership-imperative",
    "href": "posts/Artificial Intelligence and the Shifting Balance of Power/index.html#ai-as-a-leadership-imperative",
    "title": "Artificial Intelligence and the Shifting Balance of Power",
    "section": "",
    "text": "Looking ahead, AI will not merely support business operations—it will redefine them. From supply chains to customer experience to product design, every layer of business is being touched by AI. Companies that view AI as a strategic capability rather than a technological tool are the ones poised to shape entire industries.\nThe Critical & Emerging Technologies Index makes it clear: AI is no longer a technology choice—it’s a leadership decision. Companies that recognize this shift, invest accordingly, and execute thoughtfully will define the market leaders of the next decade.\nCritical and Emerging Technologies Index"
  }
]